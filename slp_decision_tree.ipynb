{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-mnist will install the required package\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from threading import Thread\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision                                 # datasets and transformations modules\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn                              # neural network module\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim                        # optimization module\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# All networks derive from the base class nn.Module\n",
    "class Perceptron(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    def __init__(self, d, K):\n",
    "        # all derived classes must call __init__ method of super class\n",
    "        super(Perceptron, self).__init__()\n",
    "        # create a fully connected layer from input to output\n",
    "        self.model = nn.Linear(d, K)\n",
    "    \n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        # flatten the image from BxCxHXW to Bx784\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.model(x.float())\n",
    "        # softmax is internally done inside cross entropy loss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGeneticForestClassifier:\n",
    "    def __init__(self, N, generation_number, class_percentage):\n",
    "        self.N = N\n",
    "        self.generation_number = generation_number\n",
    "        self.class_percentage = class_percentage\n",
    "        self.trained_trees = []\n",
    "        self.slp = None\n",
    "        self.prediction_tree = None\n",
    "        self.one_hot_encoder = None\n",
    "        # torch parameters\n",
    "        self.SEED = 0            # reproducability\n",
    "        # NN Parameters\n",
    "        self.EPOCHS = 20          # number of epochs\n",
    "        self.LR = 0.01            # learning rate\n",
    "        self.MOMENTUM = 0.9       # momentum for the optimizer\n",
    "        self.WEIGHT_DECAY = 1e-5  # weight decay for the optimizer\n",
    "        self.GAMMA = 0.1          # learning rate schedular\n",
    "        self.BATCH_SIZE = 32      # number of images to load per iteration\n",
    "        self.train_tree_batch = 20\n",
    "        self.mutation_rate = 0.4\n",
    "        self.population_list = None\n",
    "\n",
    "    def train_net(self):\n",
    "        # put the network in training mode\n",
    "        self.slp.train()\n",
    "        # keep record of the loss value\n",
    "        epoch_loss = 0.0\n",
    "        # use training data as batches\n",
    "        for xt, rt in self.train_loader:\n",
    "            # move training instances and corresponding labels into gpu if cuda is available\n",
    "            xt, rt = xt.to(self.device), rt.to(self.device)\n",
    "            # clear the previously accumulated gradients\n",
    "            self.optimizer.zero_grad() \n",
    "            # forward the network\n",
    "            yt = self.slp(xt)\n",
    "            # calculate loss\n",
    "            loss = self.loss_fn(yt, rt)\n",
    "            # make a backward pass, calculate gradients\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            self.optimizer.step()\n",
    "            # accumulate loss\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss\n",
    "        \n",
    "    def train_tree(self, filter_label, state_counter, tree_list):\n",
    "        \n",
    "        y_train_subtree = self.y_train[self.y_train.label.isin(filter_label)]\n",
    "        X_train_subtree = self.X_train.loc[y_train_subtree.index.values.tolist()]\n",
    "        \n",
    "        dtc = DecisionTreeClassifier(random_state=state_counter)\n",
    "        dtc = dtc.fit(X_train_subtree,y_train_subtree)\n",
    "        y_valid_filtered= self.y_valid[self.y_valid.label.isin(filter_label)]\n",
    "        X_valid_filtered = self.X_valid.loc[y_valid_filtered.index]\n",
    "        y_pred = dtc.predict(X_valid_filtered)\n",
    "        tree_accuracy = metrics.accuracy_score(y_valid_filtered, y_pred)\n",
    "        print(\"Accuracy of Tree\",state_counter+1,\":\",tree_accuracy)\n",
    "        print(\"Classes: \",filter_label)\n",
    "        tree_list.append({\"tree\": dtc, \"accuracy\": tree_accuracy, \"filter_label\": filter_label})   \n",
    "        \n",
    "    def fit_trees(self, filter_labels, tree_list):\n",
    "        state_counter = 0\n",
    "        train_threads = []\n",
    "        for filter_label in filter_labels:\n",
    "            train_threads.append(Thread(target=self.train_tree, args=[filter_label, state_counter, tree_list]))\n",
    "            state_counter += 1\n",
    "        for thread_index in range(0, len(train_threads), self.train_tree_batch ):\n",
    "            current_train_threads = train_threads[thread_index:thread_index+self.train_tree_batch ]\n",
    "            for train_thread in current_train_threads:\n",
    "                train_thread.start()\n",
    "            for train_thread in current_train_threads:\n",
    "                train_thread.join()\n",
    "                \n",
    "    def train_slp(self, one_hot_encoded_predictions):\n",
    "        self.d = one_hot_encoded_predictions.shape[1]      # number of input features \n",
    "        \n",
    "        print(\"SLP input dimension:\", self.d)\n",
    "        \n",
    "        # manual seed to reproduce same resultsnet\n",
    "        torch.manual_seed(self.SEED)\n",
    "        # create the network\n",
    "        self.slp = Perceptron(self.d,self.K)\n",
    "        # check if CUDA is available\n",
    "        cuda = torch.cuda.is_available()  \n",
    "        self.device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "        # if cuda is available move network into gpu\n",
    "        self.slp.to(self.device)\n",
    "        # specify the loss to be used\n",
    "        # softmax is internally computed.\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        # specify the optimizer to update the weights during backward pass\n",
    "        self.optimizer = optim.SGD(self.slp.parameters(), lr=self.LR, momentum=self.MOMENTUM, weight_decay=self.WEIGHT_DECAY)\n",
    "        # change learning rate over time\n",
    "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=self.GAMMA) #CHECK THIS\n",
    "        \n",
    "        train_target = torch.tensor(self.y_train.values.flatten().astype(np.int32)).long()\n",
    "\n",
    "        train = torch.tensor(one_hot_encoded_predictions) \n",
    "\n",
    "        train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = self.BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "        \n",
    "        # train the network\n",
    "        for epoch in range(1,self.EPOCHS+1):\n",
    "            # train network for one epoch\n",
    "            self.train_net()\n",
    "        # print(\"SLP Weights:\", self.slp.model.weight)\n",
    "        \n",
    "        \n",
    "    def one_hot_encode(self):\n",
    "        total_predictions = self.trained_trees[0].predict(self.X_train)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i].predict(self.X_train)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        self.one_hot_encoder = OneHotEncoder(handle_unknown='ignore') \n",
    "        self.one_hot_encoder.fit(total_predictions)\n",
    "        \n",
    "        one_hot_encoded_predictions = self.one_hot_encoder.transform(total_predictions).toarray() \n",
    "        return one_hot_encoded_predictions\n",
    "\n",
    "    \n",
    "    def train_prediction_tree(self, one_hot_encoded_predictions):\n",
    "        self.prediction_tree = DecisionTreeClassifier(random_state=200)\n",
    "        self.prediction_tree = self.prediction_tree.fit(one_hot_encoded_predictions, self.y_train)\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.sample_count = y_train.shape[0]\n",
    "        self.K = self.label_count              # number of output features\n",
    "        \n",
    "        self.population_list = self.genetic_find_parameters()\n",
    "        last_population = self.population_list[-1]\n",
    "        \n",
    "        self.trained_trees = [member['tree'] for member in last_population]\n",
    "        \n",
    "        one_hot_encoded_predictions = self.one_hot_encode()\n",
    "        self.train_slp(one_hot_encoded_predictions)\n",
    "        self.train_prediction_tree(one_hot_encoded_predictions)\n",
    "        \n",
    "    def model_analysis(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.sample_count = y_train.shape[0]\n",
    "        self.K = self.label_count              # number of output features\n",
    "        \n",
    "        self.population_list = self.genetic_find_parameters()\n",
    "        \n",
    "        majority_accuracies = []\n",
    "        slp_accuracies = []\n",
    "        prediction_tree_accuracies = []\n",
    "        population_mean_accuracies = []\n",
    "        \n",
    "        for population in self.population_list:\n",
    "            \n",
    "            population_mean_accuracy = np.mean(np.asarray([member['accuracy'] for member in population]))\n",
    "            population_mean_accuracies.append(population_mean_accuracy)\n",
    "\n",
    "            self.trained_trees = [member['tree'] for member in population]\n",
    "            one_hot_encoded_predictions = self.one_hot_encode()\n",
    "            self.train_slp(one_hot_encoded_predictions)\n",
    "            self.train_prediction_tree(one_hot_encoded_predictions)\n",
    "            \n",
    "            majority_voting_pred = self.majority_voting_predict(X_test)\n",
    "            slp_pred = self.slp_predict(X_test)\n",
    "            prediction_tree_predict = self.prediction_tree_predict(X_test)\n",
    "            \n",
    "            majority_accuracy = metrics.accuracy_score(y_test, majority_voting_pred)\n",
    "            slp_accuracy = metrics.accuracy_score(y_test, slp_pred)\n",
    "            prediction_tree_accuracy = metrics.accuracy_score(y_test, prediction_tree_predict)\n",
    "            \n",
    "            majority_accuracies.append(majority_accuracy)\n",
    "            slp_accuracies.append(slp_accuracy)\n",
    "            prediction_tree_accuracies.append(prediction_tree_accuracy)\n",
    "        \n",
    "        generation_numbers = np.arange(len(self.population_list))\n",
    "        \n",
    "        \n",
    "        plt.plot(generation_numbers, prediction_tree_accuracies, label = \"Prediction Tree\")\n",
    "        plt.plot(generation_numbers, slp_accuracies, label = \"SLP\")\n",
    "        plt.plot(generation_numbers, majority_accuracies, label = \"Majority\")\n",
    "        plt.plot(generation_numbers, population_mean_accuracies, label = \"Population Mean\")\n",
    "        plt.title(\"Accuracies in Generations\")\n",
    "        plt.xlabel(\"Generation Number\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def majority_voting_predict(self, X_test):\n",
    "        total_predictions = self.forest_trees_predict(X_test)\n",
    "        # Majority Voting\n",
    "        predicted_values = []\n",
    "        for row in total_predictions:\n",
    "            majority_vote = np.bincount(row).argmax()\n",
    "            predicted_values.append(majority_vote)\n",
    "        y_pred_class = np.asarray(predicted_values)\n",
    "        return y_pred_class\n",
    "    \n",
    "    def slp_predict(self, X_test):\n",
    "        total_predictions = self.forest_trees_predict(X_test)\n",
    "        # SLP\n",
    "        one_hot_encoded_predictions = self.one_hot_encoder.transform(total_predictions).toarray() \n",
    "        test = torch.tensor(one_hot_encoded_predictions) \n",
    "        y_pred = self.slp(test.to(self.device))\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred_class = np.asarray([np.argmax(pred) for pred in y_pred])\n",
    "        return y_pred_class\n",
    "    \n",
    "    def prediction_tree_predict(self, X_test):\n",
    "        total_predictions = self.forest_trees_predict(X_test)\n",
    "        # Prediction Tree\n",
    "        one_hot_encoded_predictions = self.one_hot_encoder.transform(total_predictions).toarray() \n",
    "        y_pred_class = self.prediction_tree.predict(one_hot_encoded_predictions)\n",
    "        return y_pred_class\n",
    "    \n",
    "    def forest_trees_predict(self, X_test):\n",
    "        total_predictions = self.trained_trees[0].predict(X_test)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i].predict(X_test)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        return total_predictions\n",
    "    \n",
    "    \n",
    "    # Genetic algorithm  \n",
    "    def generate_parent_samples(self):\n",
    "        generation = []\n",
    "        for i in range(self.N):\n",
    "            generation.append(np.random.choice(range(self.label_count), round(self.label_count*self.class_percentage), replace=False))\n",
    "        return generation  \n",
    "\n",
    "\n",
    "    def genetic_find_parameters(self):\n",
    "        generation = self.generate_parent_samples()\n",
    "        population_list = []\n",
    "        for i in range(self.generation_number+1):\n",
    "            trained_tree_results = []\n",
    "            self.fit_trees(generation, trained_tree_results)\n",
    "            population_list.append(trained_tree_results)\n",
    "            generation = self.evolve(trained_tree_results)\n",
    "            print(\"Gen:\",i)\n",
    "        return population_list\n",
    "    \n",
    "        \n",
    "    def evolve(self, trained_tree_results):\n",
    "        \n",
    "        trained_tree_results_sorted = sorted(trained_tree_results, key=itemgetter(\"accuracy\"), reverse=True)\n",
    "        \n",
    "        next_generation = []\n",
    "        \n",
    "        # Elitism\n",
    "        next_generation.append(trained_tree_results_sorted[0][\"filter_label\"])\n",
    "        child_num = 1\n",
    "        while(child_num < len(trained_tree_results)):\n",
    "            parent_1 = self.tournament(trained_tree_results)\n",
    "            parent_2 = self.tournament(trained_tree_results)\n",
    "            child = self.crossover(parent_1, parent_2)\n",
    "            self.mutate(child)\n",
    "            if list(child) not in np.array(next_generation).tolist():          \n",
    "                next_generation.append(child)\n",
    "                child_num += 1         \n",
    "        return next_generation\n",
    "\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        parents_merged = np.unique(np.append(parent1, parent2))\n",
    "        child = np.random.choice(parents_merged, len(parent1), replace=False)\n",
    "        return np.sort(child)\n",
    "\n",
    "    \n",
    "    def mutate(self, child):\n",
    "        mutated_child = []\n",
    "        if len(child) == self.label_count:\n",
    "            return child\n",
    "        non_existing_labels = []\n",
    "        for label in range(self.label_count):\n",
    "            if label not in child:\n",
    "                non_existing_labels.append(label)\n",
    "        for gen in child:\n",
    "            if np.random.random() < self.mutation_rate:\n",
    "                selected_label_index = np.random.randint(len(non_existing_labels))\n",
    "                mutated_child.append(non_existing_labels.pop(selected_label_index))\n",
    "            else:\n",
    "                mutated_child.append(gen)\n",
    "        return np.sort(mutated_child)\n",
    "\n",
    "    def tournament(self, generation):\n",
    "        # print(\"*********** Tournament ***********\")\n",
    "        accuracies = np.asarray([tree[\"accuracy\"] for tree in generation])\n",
    "        accuracies -= np.min(accuracies)\n",
    "        probabilities = np.asarray(accuracies)/sum(accuracies)\n",
    "        # print(\"Probabilities:\",probabilities)\n",
    "        selected = np.random.choice(generation, 1, p=probabilities)[0][\"filter_label\"]\n",
    "        # print(\"Selected:\", selected)\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(60) # reproducability\n",
    "\n",
    "def mnist_dataset_read(path):\n",
    "    mndata = MNIST(path)\n",
    "\n",
    "    # read training images and corresponding labels\n",
    "    tr_images, tr_labels = mndata.load_training()\n",
    "    # read test images and corresponding labels\n",
    "    tt_images, tt_labels = mndata.load_testing()\n",
    "\n",
    "    # convert lists into numpy format and apply normalization\n",
    "    tr_images = np.array(tr_images) / 255. # shape (60000, 784)\n",
    "    tr_labels = np.array(tr_labels)         # shape (60000,)\n",
    "    tt_images = np.array(tt_images) / 255. # shape (10000, 784)\n",
    "    tt_labels = np.array(tt_labels)         # shape (10000,)\n",
    "\n",
    "    columns_images = ['p{}'.format(i+1) for i in range(784)]\n",
    "    X_train = pd.DataFrame(data=tr_images, columns=columns_images)\n",
    "    y_train = pd.DataFrame(data=tr_labels, columns=['label'])\n",
    "    X_test = pd.DataFrame(data=tt_images, columns=columns_images)\n",
    "    y_test = pd.DataFrame(data=tt_labels, columns=['label'])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_data(btch):\n",
    "    labels = btch[b'labels']\n",
    "    imgs = btch[b'data'].reshape((-1, 32, 32, 3))\n",
    "    \n",
    "    res = []\n",
    "    for ii in range(imgs.shape[0]):\n",
    "        img = imgs[ii].copy()\n",
    "        #img = np.transpose(img.flatten().reshape(3,32,32))\n",
    "        img = np.fliplr(np.rot90(np.transpose(img.flatten().reshape(3,32,32)), k=-1))\n",
    "        res.append(img)\n",
    "    imgs = np.stack(res)\n",
    "    return labels, imgs\n",
    "\n",
    "def load_data_cifar():\n",
    "    batch1 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_5\")\n",
    "    test_batch = unpickle(\"Datasets/cifar-10-batches-py/test_batch\")\n",
    "    \n",
    "    pixel_num = 32*32*3\n",
    "    x_train_l = []\n",
    "    y_train_l = []\n",
    "    for ibatch in [batch1, batch2, batch3, batch4, batch5]:\n",
    "        labels, imgs = load_data(ibatch)\n",
    "        x_train_l.append(imgs)\n",
    "        y_train_l.extend(labels)\n",
    "    x_train = np.vstack(x_train_l)\n",
    "    y_train = np.vstack(y_train_l)\n",
    "    \n",
    "    x_test_l = []\n",
    "    y_test_l = []\n",
    "    labels, imgs = load_data(test_batch)\n",
    "    x_test_l.append(imgs)\n",
    "    y_test_l.extend(labels)\n",
    "    x_test = np.vstack(x_test_l)\n",
    "    y_test = np.vstack(y_test_l)\n",
    "    \n",
    "    del batch1, batch2, batch3, batch4, batch5, test_batch\n",
    "    \n",
    "    # imgplot = plt.imshow(x_train[58])\n",
    "    \n",
    "    x_train, x_test = x_train.reshape(-1, pixel_num), x_test.reshape(-1, pixel_num)\n",
    "    \n",
    "    columns_images = ['p{}'.format(i+1) for i in range(pixel_num)]\n",
    "    X_train = pd.DataFrame(data=x_train, columns=columns_images)\n",
    "    y_train = pd.DataFrame(data=y_train, columns=['label'])\n",
    "    X_test = pd.DataFrame(data=x_test, columns=columns_images)\n",
    "    y_test = pd.DataFrame(data=y_test, columns=['label'])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(X_train, X_test, y_train, y_test):\n",
    "    cgfc = CustomGeneticForestClassifier(N=5, generation_number=5, class_percentage = 0.5)\n",
    "    cgfc.fit(X_train, y_train)\n",
    "    slp_pred=cgfc.slp_predict(X_test)\n",
    "    prediction_tree_pred=cgfc.prediction_tree_predict(X_test)\n",
    "    majority_voting_pred=cgfc.majority_voting_predict(X_test)\n",
    "\n",
    "    print(\"SLP Pred: \", metrics.accuracy_score(y_test, slp_pred))\n",
    "    print(\"Prediction Tree Pred: \", metrics.accuracy_score(y_test, prediction_tree_pred))\n",
    "    print(\"Majority Voting Pred: \", metrics.accuracy_score(y_test, majority_voting_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "xX_train, xX_valid, yy_train, yy_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "rf.fit(xX_train,yy_train)\n",
    "pred=rf.predict(xX_valid)\n",
    "print(metrics.accuracy_score(yy_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_train, m_X_test, m_y_train, m_y_test = mnist_dataset_read('Datasets/MNIST')\n",
    "fm_X_train, fm_X_test, fm_y_train, fm_y_test = mnist_dataset_read('Datasets/Fashion_MNIST')\n",
    "cf_X_train, cf_y_train, cf_X_test, cf_y_test = load_data_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Tree 2 : 0.8708493242115801\n",
      "Classes:  [1 3 9 6 0]\n",
      "Accuracy of Tree 4 : 0.8828843901622888\n",
      "Classes:  [7 9 1 4 2]\n",
      "Accuracy of Tree 3 : 0.8954900981860543\n",
      "Classes:  [1 9 6 8 4]\n",
      "Accuracy of Tree 5 : 0.9485610320873304\n",
      "Classes:  [3 1 5 8 2]\n",
      "Accuracy of Tree 1 : 0.9106786427145709\n",
      "Classes:  [5 8 7 4 9]\n",
      "Gen: 0\n",
      "Accuracy of Tree 5 : 0.8820478500920194\n",
      "Classes:  [1 2 4 7 9]\n",
      "Accuracy of Tree 1 : 0.9449222626529937\n",
      "Classes:  [3 1 5 8 2]\n",
      "Accuracy of Tree 2 : 0.9469070459808138\n",
      "Classes:  [1 2 3 5 8]\n",
      "Accuracy of Tree 4 : 0.895173328910267\n",
      "Classes:  [1 2 4 8 9]\n",
      "Accuracy of Tree 3 : 0.9153359946773121\n",
      "Classes:  [4 5 7 8 9]\n",
      "Gen: 1\n",
      "Accuracy of Tree 2 : 0.9506441358541075\n",
      "Classes:  [1 2 5 7 8]\n",
      "Accuracy of Tree 1 : 0.9449222626529937\n",
      "Classes:  [1 2 3 5 8]\n",
      "Accuracy of Tree 5 : 0.8949983438224578\n",
      "Classes:  [1 2 4 5 8]\n",
      "Accuracy of Tree 3 : 0.911681386435594\n",
      "Classes:  [2 5 7 8 9]\n",
      "Accuracy of Tree 4 : 0.9155023286759814\n",
      "Classes:  [4 5 7 8 9]\n",
      "Gen: 2\n",
      "Accuracy of Tree 5 : 0.9490137077900368\n",
      "Classes:  [1 2 3 7 8]\n",
      "Accuracy of Tree 3 : 0.9321695760598504\n",
      "Classes:  [2 3 5 7 8]\n",
      "Accuracy of Tree 1 : 0.9479672076292455\n",
      "Classes:  [1 2 5 7 8]\n",
      "Accuracy of Tree 4 : 0.911681386435594\n",
      "Classes:  [2 5 7 8 9]\n",
      "Accuracy of Tree 2 : 0.9143379906852961\n",
      "Classes:  [4 5 7 8 9]\n",
      "Gen: 3\n",
      "Accuracy of Tree 3 : 0.9372915276851234\n",
      "Classes:  [1 3 5 7 8]\n",
      "Accuracy of Tree 1 : 0.9486793714476763\n",
      "Classes:  [1 2 3 7 8]\n",
      "Accuracy of Tree 5 : 0.9431097764431098\n",
      "Classes:  [1 2 3 5 7]\n",
      "Accuracy of Tree 2 : 0.9506441358541075\n",
      "Classes:  [1 2 5 7 8]\n",
      "Accuracy of Tree 4 : 0.9483956334766788\n",
      "Classes:  [1 2 3 5 8]\n",
      "Gen: 4\n",
      "Accuracy of Tree 2 : 0.9396264176117411\n",
      "Classes:  [1 3 5 7 8]\n",
      "Accuracy of Tree 4 : 0.9468405215646941\n",
      "Classes:  [1 2 3 7 8]\n",
      "Accuracy of Tree 3 : 0.9321695760598504\n",
      "Classes:  [2 3 5 7 8]\n",
      "Accuracy of Tree 1 : 0.9479672076292455\n",
      "Classes:  [1 2 5 7 8]\n",
      "Accuracy of Tree 5 : 0.9485610320873304\n",
      "Classes:  [1 2 3 5 8]\n",
      "Gen: 5\n",
      "SLP input dimension: 25\n",
      "SLP input dimension: 25\n",
      "SLP input dimension: 25\n",
      "SLP input dimension: 25\n",
      "SLP input dimension: 25\n",
      "SLP input dimension: 25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cgfc = CustomGeneticForestClassifier(N=5, generation_number=5, class_percentage = 0.5)\n",
    "cgfc.model_analysis(fm_X_train, fm_y_train, fm_X_test, fm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "print(\"MNIST\\n\")\n",
    "run_test(m_X_train, m_X_test, m_y_train, m_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion MNIST\n",
      "\n",
      "Accuracy of Tree 2 : 0.9354571096731376\n",
      "Classes:  [1 0 5 3 9]\n",
      "Accuracy of Tree 1 : 0.9458459468550285\n",
      "Classes:  [9 7 8 0 1]\n",
      "Accuracy of Tree 3 : 0.9145086321381142\n",
      "Classes:  [1 9 0 4 3]\n",
      "Accuracy of Tree 5 : 0.8666556782594363\n",
      "Classes:  [3 2 4 9 8]\n",
      "Accuracy of Tree 4 : 0.7590201919894075\n",
      "Classes:  [2 8 6 4 3]\n",
      "Gen: 0\n",
      "Accuracy of Tree 1 : 0.9458459468550285\n",
      "Classes:  [9 7 8 0 1]\n",
      "Accuracy of Tree 5 : 0.9438277833837874\n",
      "Classes:  [0 1 7 8 9]\n",
      "Accuracy of Tree 3 : 0.9525790349417638\n",
      "Classes:  [0 1 5 8 9]\n",
      "Accuracy of Tree 4 : 0.8669853304763474\n",
      "Classes:  [2 3 4 8 9]\n",
      "Accuracy of Tree 2 : 0.9146442133069176\n",
      "Classes:  [0 3 4 5 9]\n",
      "Gen: 1\n",
      "Accuracy of Tree 3 : 0.9372915276851234\n",
      "Classes:  [1 3 5 7 8]\n",
      "Accuracy of Tree 2 : 0.9456777665657585\n",
      "Classes:  [0 1 7 8 9]\n",
      "Accuracy of Tree 1 : 0.9517470881863561\n",
      "Classes:  [0 1 5 8 9]\n",
      "Accuracy of Tree 4 : 0.9172857850421\n",
      "Classes:  [0 3 4 5 9]\n",
      "Accuracy of Tree 5 : 0.9130289346044489\n",
      "Classes:  [0 5 7 8 9]\n",
      "Gen: 2\n",
      "Accuracy of Tree 4 : 0.9404603068712475\n",
      "Classes:  [1 3 5 7 8]\n",
      "Accuracy of Tree 2 : 0.9456777665657585\n",
      "Classes:  [0 1 7 8 9]\n",
      "Accuracy of Tree 3 : 0.9172517552657974\n",
      "Classes:  [1 5 7 8 9]\n",
      "Accuracy of Tree 1 : 0.9517470881863561\n",
      "Classes:  [0 1 5 8 9]\n",
      "Accuracy of Tree 5 : 0.943803311590567\n",
      "Classes:  [1 4 7 8 9]\n",
      "Gen: 3\n",
      "Accuracy of Tree 3 : 0.9221366376423309\n",
      "Classes:  [0 1 3 5 7]\n",
      "Accuracy of Tree 2 : 0.9456777665657585\n",
      "Classes:  [0 1 7 8 9]\n",
      "Accuracy of Tree 4 : 0.9496221662468514\n",
      "Classes:  [0 1 5 7 8]\n",
      "Accuracy of Tree 1 : 0.9517470881863561\n",
      "Classes:  [0 1 5 8 9]\n",
      "Accuracy of Tree 5 : 0.9130289346044489\n",
      "Classes:  [0 5 7 8 9]\n",
      "Gen: 4\n",
      "Accuracy of Tree 5 : 0.9222893588452501\n",
      "Classes:  [0 1 5 7 9]\n",
      "Accuracy of Tree 3 : 0.9473595694584594\n",
      "Classes:  [0 1 7 8 9]\n",
      "Accuracy of Tree 4 : 0.9496221662468514\n",
      "Classes:  [0 1 5 7 8]\n",
      "Accuracy of Tree 1 : 0.9517470881863561\n",
      "Classes:  [0 1 5 8 9]\n",
      "Accuracy of Tree 2 : 0.9140324468974745\n",
      "Classes:  [0 5 7 8 9]\n",
      "Gen: 5\n",
      "SLP input dimension: 25\n",
      "SLP Pred:  0.6636\n",
      "Prediction Tree Pred:  0.6485\n",
      "Majority Voting Pred:  0.5679\n"
     ]
    }
   ],
   "source": [
    "# Fashion MNIST\n",
    "print(\"Fashion MNIST\\n\")\n",
    "run_test(fm_X_train, fm_X_test, fm_y_train, fm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cifar\n",
    "print(\"Cifar\\n\")\n",
    "run_test(cf_X_train, cf_X_test, cf_y_train, cf_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
