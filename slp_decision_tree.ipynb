{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-mnist will install the required package\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision                                 # datasets and transformations modules\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn                              # neural network module\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim                        # optimization module\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# All networks derive from the base class nn.Module\n",
    "class Perceptron(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    def __init__(self, d, K):\n",
    "        # all derived classes must call __init__ method of super class\n",
    "        super(Perceptron, self).__init__()\n",
    "        # create a fully connected layer from input to output\n",
    "        self.model = nn.Linear(d, K)\n",
    "\n",
    "    \n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        # flatten the image from BxCxHXW to Bx784\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.model(x.float())\n",
    "        # softmax is internally done inside cross entropy loss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlpGeneticForestClassifier:\n",
    "    def __init__(self, N, generation_number):\n",
    "        self.N = N\n",
    "        self.generation_number = generation_number\n",
    "        self.trained_trees = []  \n",
    "        # torch parameters\n",
    "        self.SEED = 0            # reproducability\n",
    "        # NN Parameters\n",
    "        self.EPOCHS = 10          # number of epochs\n",
    "        self.LR = 0.01            # learning rate\n",
    "        self.MOMENTUM = 0.9       # momentum for the optimizer\n",
    "        self.WEIGHT_DECAY = 1e-5  # weight decay for the optimizer\n",
    "        self.GAMMA = 0.1          # learning rate schedular\n",
    "        self.BATCH_SIZE = 64      # number of images to load per iteration\n",
    "\n",
    "    def train_net(self):\n",
    "        # put the network in training mode\n",
    "        self.slp.train()\n",
    "        # keep record of the loss value\n",
    "        epoch_loss = 0.0\n",
    "        # use training data as batches\n",
    "        for xt, rt in self.train_loader:\n",
    "            # move training instances and corresponding labels into gpu if cuda is available\n",
    "            xt, rt = xt.to(self.device), rt.to(self.device)\n",
    "            # clear the previously accumulated gradients\n",
    "            self.optimizer.zero_grad() \n",
    "            # forward the network\n",
    "            yt = self.slp(xt)\n",
    "            # calculate loss\n",
    "            loss = self.loss_fn(yt, rt)\n",
    "            # make a backward pass, calculate gradients\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            self.optimizer.step()\n",
    "            # accumulate loss\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss\n",
    "    \n",
    "    def train_tree(self, tree_parameter, state_counter):\n",
    "        X_train_subtree = self.X_train.sample(frac=1, replace=True, random_state=state_counter)\n",
    "        Y_train_subtree = self.y_train.sample(frac=1, replace=True, random_state=state_counter)\n",
    "        dtc = DecisionTreeClassifier(**tree_parameter, random_state=state_counter)\n",
    "        dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "        y_pred = dtc.predict(self.X_valid)\n",
    "        print(\"Accuracy of Tree\",state_counter+1,\":\",metrics.accuracy_score(self.y_valid, y_pred))\n",
    "        self.trained_trees.append(dtc)\n",
    "        \n",
    "\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.sample_count = y_train.shape[0]\n",
    "        self.K = self.label_count              # number of output features\n",
    "        tree_parameters = self.genetic_find_parameters()\n",
    "        state_counter = 0\n",
    "        train_threads = []\n",
    "        for tree_parameter in tree_parameters:\n",
    "            train_threads.append(Thread(target=self.train_tree, args=[tree_parameter, state_counter]))\n",
    "            state_counter += 1\n",
    "        for thread in train_threads:\n",
    "            thread.start()\n",
    "        for thread in train_threads:\n",
    "            thread.join()\n",
    "    \n",
    "        total_predictions = self.trained_trees[0].predict(self.X_train)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i].predict(self.X_train)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore') \n",
    "        enc.fit(total_predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "        one_hot_encoded_predictions = enc.transform(total_predictions).toarray() \n",
    "        \n",
    "        self.d = one_hot_encoded_predictions.shape[1]      # number of input features \n",
    "        \n",
    "        # manual seed to reproduce same resultsnet\n",
    "        torch.manual_seed(self.SEED)\n",
    "        # create the network\n",
    "        self.slp = Perceptron(self.d,self.K)\n",
    "        # check if CUDA is available\n",
    "        cuda = torch.cuda.is_available()  \n",
    "        self.device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "        # if cuda is available move network into gpu\n",
    "        self.slp.to(self.device)\n",
    "        # specify the loss to be used\n",
    "        # softmax is internally computed.\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        # specify the optimizer to update the weights during backward pass\n",
    "        self.optimizer = optim.SGD(self.slp.parameters(), lr=self.LR, momentum=self.MOMENTUM, weight_decay=self.WEIGHT_DECAY)\n",
    "        # change learning rate over time\n",
    "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=self.GAMMA) #CHECK THIS\n",
    "        \n",
    "        \n",
    "        train_target = torch.tensor(self.y_train.values.flatten().astype(np.int32)).long()\n",
    "\n",
    "        train = torch.tensor(one_hot_encoded_predictions) \n",
    "\n",
    "        train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = self.BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "        \n",
    "        # train the network\n",
    "        for epoch in range(1,self.EPOCHS+1):\n",
    "            # train network for one epoch\n",
    "            self.train_net()\n",
    "\n",
    "\n",
    "    # Genetic algorithm\n",
    "    def genetic_find_parameters(self):\n",
    "        generation = self.generate_parent_samples()\n",
    "        print(\"Generation\\n\",\"*\"*50)\n",
    "        print(generation)\n",
    "        print(\"*\"*50)\n",
    "        # for i in range(self.generation_number):\n",
    "        #     generation = self.evolve(generation)\n",
    "        return generation\n",
    "\n",
    "\n",
    "    def generate_parent_samples(self):\n",
    "        generation = []\n",
    "        for i in range(self.N):\n",
    "            generation.append({\n",
    "                \"max_depth\":  np.random.normal(np.log2(self.sample_count)*2, np.log2(self.sample_count), 1),\n",
    "                \"min_samples_split\": np.random.randint(2,self.label_count),\n",
    "                \"min_samples_leaf\": np.random.randint(2,self.label_count),\n",
    "                \"max_leaf_nodes\": np.random.randint(10, self.sample_count),\n",
    "            })\n",
    "        return generation\n",
    "    \n",
    "    \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        total_predictions = self.trained_trees[0].predict(X_test)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i].predict(X_test)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        \n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(total_predictions)\n",
    "        one_hot_encoded_predictions = enc.transform(total_predictions).toarray() \n",
    "        test = torch.tensor(one_hot_encoded_predictions) \n",
    "        y_pred = self.slp(test.to(self.device))\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred_class = np.asarray([np.argmax(pred) for pred in y_pred])\n",
    "      \n",
    "        return y_pred_class\n",
    "            \n",
    "        \n",
    "    def evolve(self, generation):\n",
    "        accuracies = []\n",
    "        for tree_parameter in generation:     \n",
    "            X_train_subtree = self.X_train.sample(frac=1, replace=True, random_state=i)\n",
    "            Y_train_subtree = self.y_train.sample(frac=1, replace=True, random_state=i)\n",
    "            dtc = DecisionTreeClassifier(**tree_parameter)\n",
    "            dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "            y_pred = dtc.predict(self.X_valid)\n",
    "            accuracies.append(metrics.accuracy_score(self.y_valid, y_pred))\n",
    "        \n",
    "        next_generation = []\n",
    "        max_accuracy_index = np.argmax(accuracies)\n",
    "        next_generation.append(generation[max_accuracy_index])\n",
    "    \n",
    "        for i in range(1, self.N):\n",
    "            parent_1 = self.tournament(generation)\n",
    "            parent_2 = self.tournament(generation)\n",
    "            child = self.crossover(parent_1, parent_2)\n",
    "            self.mutate(child)\n",
    "            next_generation.append(child)\n",
    "        return next_generation\n",
    "\n",
    "    \n",
    "    def crossover(self, tree1, tree2):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def mutate(self, tree):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def tournament(self, trees):\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(60) # reproducability\n",
    "mndata = MNIST('Datasets/MNIST')\n",
    "\n",
    "# read training images and corresponding labels\n",
    "tr_images, tr_labels = mndata.load_training()\n",
    "# read test images and corresponding labels\n",
    "tt_images, tt_labels = mndata.load_testing()\n",
    "\n",
    "# convert lists into numpy format and apply normalization\n",
    "tr_images = np.array(tr_images) / 255. # shape (60000, 784)\n",
    "tr_labels = np.array(tr_labels)         # shape (60000,)\n",
    "tt_images = np.array(tt_images) / 255. # shape (10000, 784)\n",
    "tt_labels = np.array(tt_labels)         # shape (10000,)\n",
    "\n",
    "columns_images = ['p{}'.format(i+1) for i in range(784)]\n",
    "tr_df_images = pd.DataFrame(data=tr_images, columns=columns_images)\n",
    "tr_df_labels = pd.DataFrame(data=tr_labels, columns=['label'])\n",
    "tt_df_images = pd.DataFrame(data=tt_images, columns=columns_images)\n",
    "tt_df_labels = pd.DataFrame(data=tt_labels, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tr_df_images, tr_df_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0, max_depth = 30, min_samples_split = 2, min_samples_leaf=2, max_leaf_nodes=1000, min_impurity_decrease=0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8724166666666666\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "dtc = dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-3eaacaaf0fd9>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=30)\n",
    "rf.fit(X_train,y_train)\n",
    "pred=rf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation\n",
      " **************************************************\n",
      "[{'max_depth': array([2.40149385]), 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_leaf_nodes': 44471}, {'max_depth': array([31.1458573]), 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_leaf_nodes': 46403}, {'max_depth': array([20.61144699]), 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_leaf_nodes': 13925}, {'max_depth': array([34.49369961]), 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_leaf_nodes': 40815}, {'max_depth': array([31.52259731]), 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_leaf_nodes': 41306}, {'max_depth': array([35.4554778]), 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_leaf_nodes': 19584}, {'max_depth': array([30.65578675]), 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_leaf_nodes': 45317}, {'max_depth': array([27.0039844]), 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_leaf_nodes': 10813}, {'max_depth': array([37.81818757]), 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_leaf_nodes': 47377}, {'max_depth': array([29.67374994]), 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_leaf_nodes': 20720}, {'max_depth': array([29.36107515]), 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_leaf_nodes': 19874}, {'max_depth': array([26.85908301]), 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_leaf_nodes': 10505}, {'max_depth': array([19.90774716]), 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_leaf_nodes': 126}, {'max_depth': array([27.73318658]), 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_leaf_nodes': 41233}, {'max_depth': array([45.39567144]), 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_leaf_nodes': 7739}, {'max_depth': array([37.88027138]), 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_leaf_nodes': 15603}, {'max_depth': array([25.59797002]), 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_leaf_nodes': 22308}, {'max_depth': array([23.10691506]), 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_leaf_nodes': 20959}, {'max_depth': array([3.47918821]), 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_leaf_nodes': 30794}, {'max_depth': array([29.65443329]), 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_leaf_nodes': 35147}, {'max_depth': array([47.48210601]), 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_leaf_nodes': 28428}, {'max_depth': array([7.40594252]), 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_leaf_nodes': 41504}, {'max_depth': array([21.10581357]), 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_leaf_nodes': 14744}, {'max_depth': array([69.83884041]), 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_leaf_nodes': 40556}, {'max_depth': array([57.57539402]), 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_leaf_nodes': 14769}, {'max_depth': array([31.79038202]), 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_leaf_nodes': 24176}, {'max_depth': array([36.61493245]), 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_leaf_nodes': 25821}, {'max_depth': array([13.12241779]), 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_leaf_nodes': 18037}, {'max_depth': array([19.89275734]), 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_leaf_nodes': 15908}, {'max_depth': array([14.33594699]), 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_leaf_nodes': 2989}]\n",
      "**************************************************\n",
      "Accuracy of Tree 1 : 0.34197916666666667\n",
      "Accuracy of Tree 19 : 0.45989583333333334\n",
      "Accuracy of Tree 22 : 0.7701041666666667\n",
      "Accuracy of Tree 13 : 0.7860416666666666\n",
      "Accuracy of Tree 28 : 0.8476041666666667\n",
      "Accuracy of Tree 3 : 0.844375\n",
      "Accuracy of Tree 2 : 0.8360416666666667\n",
      "Accuracy of Tree 8 : 0.8428125\n",
      "Accuracy of Tree 12 : 0.8404166666666667\n",
      "Accuracy of Tree 30 : 0.8452083333333333\n",
      "Accuracy of Tree 5 : 0.8392708333333333\n",
      "Accuracy of Tree 7 : 0.8392708333333333\n",
      "Accuracy of Tree 6 : 0.8409375\n",
      "Accuracy of Tree 4 : 0.8494791666666667\n",
      "Accuracy of Tree 11 : 0.8439583333333334\n",
      "Accuracy of Tree 29 : 0.838125\n",
      "Accuracy of Tree 15 : 0.8386458333333333\n",
      "Accuracy of Tree 14 : 0.8419791666666666\n",
      "Accuracy of Tree 23 : 0.8453125\n",
      "Accuracy of Tree 16 : 0.8404166666666667\n",
      "Accuracy of Tree 18 : 0.8405208333333334\n",
      "Accuracy of Tree 20 : 0.8447916666666667\n",
      "Accuracy of Tree 10 : 0.8398958333333333\n",
      "Accuracy of Tree 24 : 0.8439583333333334\n",
      "Accuracy of Tree 25 : 0.8445833333333334\n",
      "Accuracy of Tree 27 : 0.8447916666666667\n",
      "Accuracy of Tree 17 : 0.839375\n",
      "Accuracy of Tree 9 : 0.8441666666666666\n",
      "Accuracy of Tree 21 : 0.8314583333333333\n",
      "Accuracy of Tree 26 : 0.8383333333333334\n",
      "0.9475\n"
     ]
    }
   ],
   "source": [
    "sgfc = SlpGeneticForestClassifier(N=30, generation_number=20)\n",
    "sgfc.fit(X_train, y_train)\n",
    "pred=sgfc.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(np.array([[1, 0], [1,1],[2,2],[1,3],[1,4],[1,5],[1,6],[1,7],[1,8],[1,9]]))\n",
    "one_hot_encoded_predictions = enc.transform(np.array([[1,1],[1,3]])).toarray() \n",
    "print(one_hot_encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
