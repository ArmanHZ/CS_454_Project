{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-mnist will install the required package\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlpGeneticForestClassifier:\n",
    "    def __init__(self, N, generation_number):\n",
    "        self.N = N\n",
    "        self.generation_number = generation_number\n",
    "        self.trained_trees = []\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        tree_parameters = self.genetic_find_parameters()\n",
    "        state_counter = 0\n",
    "        for tree_parameter in tree_parameters:\n",
    "            X_train_subtree = self.X_train.sample(frac=1, replace=True, random_state=state_counter)\n",
    "            Y_train_subtree = self.y_train.sample(frac=1, replace=True, random_state=state_counter)\n",
    "            dtc = DecisionTreeClassifier(**tree_parameter)\n",
    "            dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "            y_pred = dtc.predict(self.X_valid)\n",
    "            print(\"Accuracy of Tree\",state_counter+1,\":\",metrics.accuracy_score(self.y_valid, y_pred))\n",
    "            self.trained_trees.append(dtc)\n",
    "            state_counter += 1\n",
    "            \n",
    "    \n",
    "    # Genetic algorithm\n",
    "    def genetic_find_parameters(self):\n",
    "        generation = self.generate_parent_samples()\n",
    "        print(\"Generation\\n\",\"*\"*50)\n",
    "        print(generation)\n",
    "        print(\"*\"*50)\n",
    "        # for i in range(self.generation_number):\n",
    "        #     generation = self.evolve(generation)\n",
    "        return generation\n",
    "\n",
    "\n",
    "    def generate_parent_samples(self):\n",
    "        arg_test_values = {\n",
    "            \"max_depth\": [10**i for i in range(0,10)],\n",
    "            \"min_samples_split\": [i for i in range(2,self.label_count)],\n",
    "            \"min_samples_leaf\": [i for i in range(2,self.label_count)],\n",
    "            \"max_leaf_nodes\": [10**i for i in range(1,8)],\n",
    "            \"min_impurity_decrease\": [0]+[10**(-i) for i in range(0,10)]\n",
    "        }\n",
    "        arg_range_values = {}\n",
    "        for arg in arg_test_values:\n",
    "            print(\"\\nArg:\", arg)\n",
    "            accuracies = self.get_accuracies(arg, arg_test_values)\n",
    "            accuracies = np.asarray(accuracies)\n",
    "            max_accuracy_index = np.argmax(accuracies)\n",
    "            min_range_index = max(0, max_accuracy_index-1)\n",
    "            max_range_index = min(len(accuracies)-1, max_accuracy_index+1)\n",
    "            arg_range_values[arg] = (arg_test_values[arg][min_range_index], arg_test_values[arg][max_range_index])\n",
    "\n",
    "        print(\"arg_range_values\\n\",\"*\"*50)\n",
    "        print(arg_range_values)\n",
    "        print(\"*\"*50)\n",
    "        return self.get_best_generations(arg_range_values)\n",
    "\n",
    "\n",
    "    def get_accuracies(self, arg, arg_test_values):\n",
    "        accuracies = []\n",
    "        for test_value in arg_test_values[arg]:\n",
    "            print(test_value,\", \",end=\"\")\n",
    "            dtc = DecisionTreeClassifier(**{arg: test_value})\n",
    "            X_train_subtree = self.X_train.sample(frac=1, replace=True)\n",
    "            Y_train_subtree = self.y_train.sample(frac=1, replace=True)\n",
    "            dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "            y_pred = dtc.predict(self.X_valid)\n",
    "            accuracies.append(metrics.accuracy_score(self.y_valid, y_pred))\n",
    "        return accuracies\n",
    "\n",
    "\n",
    "    def get_best_generations(self, arg_range_values):\n",
    "        generation = []\n",
    "        for i in range(self.N):\n",
    "            generation.append({\n",
    "                \"max_depth\": np.random.randint(arg_range_values[\"max_depth\"][0],arg_range_values[\"max_depth\"][1]),\n",
    "                \"min_samples_split\": np.random.randint(arg_range_values[\"min_samples_split\"][0],arg_range_values[\"min_samples_split\"][1]),\n",
    "                \"min_samples_leaf\": np.random.randint(arg_range_values[\"min_samples_leaf\"][0],arg_range_values[\"min_samples_leaf\"][1]),\n",
    "                \"max_leaf_nodes\": np.random.randint(arg_range_values[\"max_leaf_nodes\"][0],arg_range_values[\"max_leaf_nodes\"][1]),\n",
    "                \"min_impurity_decrease\": np.random.uniform(arg_range_values[\"min_impurity_decrease\"][0],arg_range_values[\"min_impurity_decrease\"][1])\n",
    "            })\n",
    "        return generation\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        total_predictions = self.trained_trees[0].predict(X_test)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i].predict(X_test)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        predicted_values = []\n",
    "        for row in total_predictions:\n",
    "            majority_vote = np.bincount(row).argmax()\n",
    "            predicted_values.append(majority_vote)\n",
    "        return np.asarray(predicted_values)\n",
    "            \n",
    "        \n",
    "    def evolve(self, generation):\n",
    "        accuracies = []\n",
    "        for tree_parameter in generation:     \n",
    "            X_train_subtree = self.X_train.sample(frac=1, replace=True, random_state=i)\n",
    "            Y_train_subtree = self.y_train.sample(frac=1, replace=True, random_state=i)\n",
    "            dtc = DecisionTreeClassifier(**tree_parameter)\n",
    "            dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "            y_pred = dtc.predict(self.X_valid)\n",
    "            accuracies.append(metrics.accuracy_score(self.y_valid, y_pred))\n",
    "        \n",
    "        next_generation = []\n",
    "        max_accuracy_index = np.argmax(accuracies)\n",
    "        next_generation.append(generation[max_accuracy_index])\n",
    "    \n",
    "        for i in range(1, self.N):\n",
    "            parent_1 = self.tournament(generation)\n",
    "            parent_2 = self.tournament(generation)\n",
    "            child = self.crossover(parent_1, parent_2)\n",
    "            self.mutate(child)\n",
    "            next_generation.append(child)\n",
    "        return next_generation\n",
    "\n",
    "    \n",
    "    def crossover(self, tree1, tree2):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def mutate(self, tree):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def tournament(self, trees):\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(60) # reproducability\n",
    "mndata = MNIST('Datasets/MNIST')\n",
    "\n",
    "# read training images and corresponding labels\n",
    "tr_images, tr_labels = mndata.load_training()\n",
    "# read test images and corresponding labels\n",
    "tt_images, tt_labels = mndata.load_testing()\n",
    "\n",
    "# convert lists into numpy format and apply normalization\n",
    "tr_images = np.array(tr_images) / 255. # shape (60000, 784)\n",
    "tr_labels = np.array(tr_labels)         # shape (60000,)\n",
    "tt_images = np.array(tt_images) / 255. # shape (10000, 784)\n",
    "tt_labels = np.array(tt_labels)         # shape (10000,)\n",
    "\n",
    "columns_images = ['p{}'.format(i+1) for i in range(784)]\n",
    "tr_df_images = pd.DataFrame(data=tr_images, columns=columns_images)\n",
    "tr_df_labels = pd.DataFrame(data=tr_labels, columns=['label'])\n",
    "tt_df_images = pd.DataFrame(data=tt_images, columns=columns_images)\n",
    "tt_df_labels = pd.DataFrame(data=tt_labels, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tr_df_images, tr_df_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0, max_depth = 40, min_samples_split = 2, min_samples_leaf=2, max_leaf_nodes=1000, min_impurity_decrease=0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.8724166666666666\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "dtc = dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8113333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=2)\n",
    "rf.fit(X_train,y_train)\n",
    "pred=rf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Arg: max_depth\n",
      "1 , 10 , 100 , 1000 , 10000 , 100000 , 1000000 , 10000000 , 100000000 , 1000000000 , \n",
      "Arg: min_samples_split\n",
      "2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , \n",
      "Arg: min_samples_leaf\n",
      "2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , \n",
      "Arg: max_leaf_nodes\n",
      "10 , 100 , 1000 , 10000 , 100000 , 1000000 , 10000000 , \n",
      "Arg: min_impurity_decrease\n",
      "0 , 1 , 0.1 , 0.01 , 0.001 , 0.0001 , 1e-05 , 1e-06 , 1e-07 , 1e-08 , 1e-09 , arg_range_values\n",
      " **************************************************\n",
      "{'max_depth': (1, 100), 'min_samples_split': (6, 8), 'min_samples_leaf': (2, 3), 'max_leaf_nodes': (10, 1000), 'min_impurity_decrease': (0, 0.1)}\n",
      "**************************************************\n",
      "Generation\n",
      " **************************************************\n",
      "[{'max_depth': 42, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_leaf_nodes': 412, 'min_impurity_decrease': 0.01849606339770793}, {'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_leaf_nodes': 218, 'min_impurity_decrease': 0.08149549972546297}]\n",
      "**************************************************\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9e4371c527e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msgfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSlpGeneticForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msgfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-22c4316432ac>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mdtc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_subtree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_subtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of Tree\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrained_trees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mstate_counter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "sgfc = SlpGeneticForestClassifier(N=2, generation_number=20)\n",
    "sgfc.fit(X_train, y_train)\n",
    "pred=sgfc.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c1a41f08b160e8c5316af8c8759825f66bc42e51b3e7a5810edb97d91356c55b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}