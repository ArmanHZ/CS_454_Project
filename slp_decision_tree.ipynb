{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-mnist will install the required package\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from threading import Thread\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision                                 # datasets and transformations modules\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn                              # neural network module\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim                        # optimization module\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# All networks derive from the base class nn.Module\n",
    "class Perceptron(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    def __init__(self, d, K):\n",
    "        # all derived classes must call __init__ method of super class\n",
    "        super(Perceptron, self).__init__()\n",
    "        \n",
    "        # create a fully connected layer from input to output\n",
    "        self.model = nn.Linear(d, K)\n",
    "        \n",
    "        #H=100\n",
    "        #self.model = nn.Sequential(\n",
    "        #        nn.Linear(d,H),          # input to hidden layer\n",
    "        #        nn.Sigmoid(),            # hidden activation function\n",
    "        #        nn.Linear(H,K)           # hidden to output layer\n",
    "        #    )\n",
    "\n",
    "    \n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        # flatten the image from BxCxHXW to Bx784\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.model(x.float())\n",
    "        # softmax is internally done inside cross entropy loss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlpGeneticForestClassifier:\n",
    "    def __init__(self, N, generation_number, class_percentage):\n",
    "        self.N = N\n",
    "        self.generation_number = generation_number\n",
    "        self.class_percentage = class_percentage\n",
    "        self.trained_trees = []  \n",
    "        # torch parameters\n",
    "        self.SEED = 0            # reproducability\n",
    "        # NN Parameters\n",
    "        self.EPOCHS = 20          # number of epochs\n",
    "        self.LR = 0.01            # learning rate\n",
    "        self.MOMENTUM = 0.9       # momentum for the optimizer\n",
    "        self.WEIGHT_DECAY = 1e-5  # weight decay for the optimizer\n",
    "        self.GAMMA = 0.1          # learning rate schedular\n",
    "        self.BATCH_SIZE = 32      # number of images to load per iteration\n",
    "\n",
    "    def train_net(self):\n",
    "        # put the network in training mode\n",
    "        self.slp.train()\n",
    "        # keep record of the loss value\n",
    "        epoch_loss = 0.0\n",
    "        # use training data as batches\n",
    "        for xt, rt in self.train_loader:\n",
    "            # move training instances and corresponding labels into gpu if cuda is available\n",
    "            xt, rt = xt.to(self.device), rt.to(self.device)\n",
    "            # clear the previously accumulated gradients\n",
    "            self.optimizer.zero_grad() \n",
    "            # forward the network\n",
    "            yt = self.slp(xt)\n",
    "            # calculate loss\n",
    "            loss = self.loss_fn(yt, rt)\n",
    "            # make a backward pass, calculate gradients\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            self.optimizer.step()\n",
    "            # accumulate loss\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss\n",
    "        \n",
    "    def train_tree(self, filter_label, state_counter, tree_list):\n",
    "        #y_train = self.y_train.copy()\n",
    "        #X_train = self.X_train.copy()\n",
    "        #y_train.loc[~y_train.label.isin(filter_label), 'label'] = -1\n",
    "        \n",
    "        #indexes = y_train.index.values.tolist()\n",
    "        #selected_indexes = np.random.choice(indexes, len(indexes), replace=True)\n",
    "\n",
    "        #X_train_subtree = X_train.loc[selected_indexes]\n",
    "        #Y_train_subtree = y_train.loc[selected_indexes]\n",
    "        \n",
    "        \n",
    "        y_train_subset = self.y_train[self.y_train.label.isin(filter_label)]\n",
    "        Y_train_subtree = y_train_subset.sample(frac=1, replace=True, random_state=state_counter)\n",
    "        # X_train_subset = self.X_train.loc[y_train_subset.index]\n",
    "        # X_train_subtree = X_train_subset.sample(frac=1, replace=True, random_state=state_counter)\n",
    "        X_train_subtree = self.X_train.loc[Y_train_subtree.index.values.tolist()]\n",
    "       \n",
    "        \n",
    "        dtc = DecisionTreeClassifier(random_state=state_counter)\n",
    "        dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "        y_valid_filtered= self.y_valid[self.y_valid.label.isin(filter_label)]\n",
    "        X_valid_filtered = self.X_valid.loc[y_valid_filtered.index]\n",
    "        y_pred = dtc.predict(X_valid_filtered)\n",
    "        tree_accuracy = metrics.accuracy_score(y_valid_filtered, y_pred)\n",
    "        print(\"Accuracy of Tree\",state_counter+1,\":\",tree_accuracy)\n",
    "        print(\"Classes: \",filter_label)\n",
    "        tree_list.append({\"tree\": dtc, \"accuracy\": tree_accuracy, \"filter_label\": filter_label})   \n",
    "        \n",
    "    def fit_trees(self, filter_labels, tree_list, thread_batch):\n",
    "        state_counter = 0\n",
    "        train_threads = []\n",
    "        for filter_label in filter_labels:\n",
    "            train_threads.append(Thread(target=self.train_tree, args=[filter_label, state_counter, tree_list]))\n",
    "            state_counter += 1\n",
    "        for thread_index in range(0, len(train_threads), thread_batch):\n",
    "            current_train_threads = train_threads[thread_index:thread_index+thread_batch]\n",
    "            for train_thread in current_train_threads:\n",
    "                train_thread.start()\n",
    "            for train_thread in current_train_threads:\n",
    "                train_thread.join()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.sample_count = y_train.shape[0]\n",
    "        self.K = self.label_count              # number of output features\n",
    "        \n",
    "        filter_labels = self.genetic_find_parameters()\n",
    "        self.fit_trees(filter_labels, self.trained_trees, thread_batch=25)\n",
    "        \n",
    "        total_predictions = self.trained_trees[0][\"tree\"].predict(self.X_train)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i][\"tree\"].predict(self.X_train)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore') \n",
    "        enc.fit(total_predictions)\n",
    "        \n",
    "        one_hot_encoded_predictions = enc.transform(total_predictions).toarray() \n",
    "    \n",
    "        \n",
    "        self.d = one_hot_encoded_predictions.shape[1]      # number of input features \n",
    "        \n",
    "        print(\"SLP input dimension:\", self.d)\n",
    "        \n",
    "        # manual seed to reproduce same resultsnet\n",
    "        torch.manual_seed(self.SEED)\n",
    "        # create the network\n",
    "        self.slp = Perceptron(self.d,self.K)\n",
    "        # check if CUDA is available\n",
    "        cuda = torch.cuda.is_available()  \n",
    "        self.device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "        # if cuda is available move network into gpu\n",
    "        self.slp.to(self.device)\n",
    "        # specify the loss to be used\n",
    "        # softmax is internally computed.\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        # specify the optimizer to update the weights during backward pass\n",
    "        self.optimizer = optim.SGD(self.slp.parameters(), lr=self.LR, momentum=self.MOMENTUM, weight_decay=self.WEIGHT_DECAY)\n",
    "        # change learning rate over time\n",
    "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=self.GAMMA) #CHECK THIS\n",
    "        \n",
    "        \n",
    "        train_target = torch.tensor(self.y_train.values.flatten().astype(np.int32)).long()\n",
    "\n",
    "        train = torch.tensor(one_hot_encoded_predictions) \n",
    "\n",
    "        train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = self.BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "        \n",
    "        # train the network\n",
    "        for epoch in range(1,self.EPOCHS+1):\n",
    "            # train network for one epoch\n",
    "            self.train_net()\n",
    "        print(\"SLP Weights:\", self.slp.model.weight)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        total_predictions = self.trained_trees[0][\"tree\"].predict(X_test)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i][\"tree\"].predict(X_test)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        \n",
    "        \n",
    "        #predicted_values = []\n",
    "        #for row in total_predictions:\n",
    "        #    majority_vote = np.bincount(row).argmax()\n",
    "        #    predicted_values.append(majority_vote)\n",
    "        #y_pred_class = np.asarray(predicted_values)\n",
    "        \n",
    "        \n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(total_predictions)\n",
    "        one_hot_encoded_predictions = enc.transform(total_predictions).toarray() \n",
    "        test = torch.tensor(one_hot_encoded_predictions) \n",
    "        y_pred = self.slp(test.to(self.device))\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred_class = np.asarray([np.argmax(pred) for pred in y_pred])\n",
    "      \n",
    "        return y_pred_class\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Genetic algorithm  \n",
    "    def generate_parent_samples(self):\n",
    "        generation = []\n",
    "        for i in range(self.N):\n",
    "            generation.append(\n",
    "                #{\"max_depth\":  np.random.normal(np.log2(self.sample_count)*2, np.log2(self.sample_count), 1),\n",
    "                #\"min_samples_split\": np.random.randint(2,self.label_count),\n",
    "                #\"min_samples_leaf\": np.random.randint(2,self.label_count),\n",
    "                #\"max_leaf_nodes\": np.random.randint(10, self.sample_count),}\n",
    "                np.random.choice(range(self.label_count), round(self.label_count*self.class_percentage), replace=False)\n",
    "            )\n",
    "        return generation  \n",
    "\n",
    "\n",
    "    def genetic_find_parameters(self):\n",
    "        generation = self.generate_parent_samples()\n",
    "        #print(\"Generation\\n\",\"*\"*50)\n",
    "        #print(generation)\n",
    "        #print(\"*\"*50)\n",
    "        for i in range(self.generation_number):\n",
    "            generation = self.evolve(generation)\n",
    "            print(\"Gen:\",i+1)\n",
    "        return generation\n",
    "    \n",
    "        \n",
    "    def evolve(self, generation):\n",
    "        trained_tree_results = []\n",
    "        self.fit_trees(generation, trained_tree_results, thread_batch=25)\n",
    "        trained_tree_results_sorted = sorted(trained_tree_results, key=itemgetter(\"accuracy\"), reverse=True)\n",
    "        \n",
    "        next_generation = []\n",
    "        next_generation.append(trained_tree_results_sorted[0][\"filter_label\"])\n",
    "    \n",
    "        for i in range(1, len(generation)):\n",
    "            parent_1 = self.tournament(trained_tree_results)\n",
    "            parent_2 = self.tournament(trained_tree_results)\n",
    "            child = self.crossover(parent_1, parent_2)\n",
    "            # self.mutate(child)\n",
    "            next_generation.append(child)\n",
    "            \n",
    "        return next_generation\n",
    "\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        parents_merged = np.unique(np.append(parent1, parent2))\n",
    "        child = np.random.choice(parents_merged, len(parent1), replace=False)\n",
    "        return child\n",
    "\n",
    "    \n",
    "    def mutate(self, child):\n",
    "        return\n",
    "\n",
    "    \n",
    "    def tournament(self, generation):\n",
    "        # print(\"*********** Tournament ***********\")\n",
    "        accuracies = np.asarray([tree[\"accuracy\"] for tree in generation])\n",
    "        accuracies -= np.min(accuracies)\n",
    "        probabilities = np.asarray(accuracies)/sum(accuracies)\n",
    "        # print(\"Probabilities:\",probabilities)\n",
    "        selected = np.random.choice(generation, 1, p=probabilities)[0][\"filter_label\"]\n",
    "        # print(\"Selected:\", selected)\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(60) # reproducability\n",
    "mndata = MNIST('Datasets/MNIST')\n",
    "\n",
    "# read training images and corresponding labels\n",
    "tr_images, tr_labels = mndata.load_training()\n",
    "# read test images and corresponding labels\n",
    "tt_images, tt_labels = mndata.load_testing()\n",
    "\n",
    "# convert lists into numpy format and apply normalization\n",
    "tr_images = np.array(tr_images) / 255. # shape (60000, 784)\n",
    "tr_labels = np.array(tr_labels)         # shape (60000,)\n",
    "tt_images = np.array(tt_images) / 255. # shape (10000, 784)\n",
    "tt_labels = np.array(tt_labels)         # shape (10000,)\n",
    "\n",
    "columns_images = ['p{}'.format(i+1) for i in range(784)]\n",
    "tr_df_images = pd.DataFrame(data=tr_images, columns=columns_images)\n",
    "tr_df_labels = pd.DataFrame(data=tr_labels, columns=['label'])\n",
    "tt_df_images = pd.DataFrame(data=tt_images, columns=columns_images)\n",
    "tt_df_labels = pd.DataFrame(data=tt_labels, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tr_df_images, tr_df_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0, max_depth = 30, min_samples_split = 2, min_samples_leaf=2, max_leaf_nodes=1000, min_impurity_decrease=0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8724166666666666\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "dtc = dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-e79107394d5e>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(xX_train,yy_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=10)\n",
    "xX_train, xX_valid, yy_train, yy_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "rf.fit(xX_train,yy_train)\n",
    "pred=rf.predict(xX_valid)\n",
    "print(metrics.accuracy_score(yy_valid, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Tree 7 : 0.839375\n",
      "Classes:  [4 0 9 1 8 5 3 2 6 7]\n",
      "Accuracy of Tree 8 : 0.8425\n",
      "Classes:  [9 5 1 3 8 2 0 7 6 4]\n",
      "Accuracy of Tree 4 : 0.8477083333333333\n",
      "Classes:  [5 4 1 9 8 6 2 3 0 7]\n",
      "Accuracy of Tree 3 : 0.8410416666666667\n",
      "Classes:  [8 6 7 5 1 2 9 3 0 4]\n",
      "Accuracy of Tree 6 : 0.8455208333333334\n",
      "Classes:  [4 7 5 3 9 2 0 6 1 8]\n",
      "Accuracy of Tree 1 : 0.846875\n",
      "Classes:  [3 6 8 9 4 0 5 2 7 1]\n",
      "Accuracy of Tree 9 : 0.84375\n",
      "Classes:  [4 8 0 5 1 2 9 3 6 7]\n",
      "Accuracy of Tree 10 : 0.8409375\n",
      "Classes:  [3 4 2 5 9 1 6 7 0 8]\n",
      "Accuracy of Tree 2 : 0.8316666666666667\n",
      "Classes:  [8 1 9 0 7 5 2 4 3 6]\n",
      "Accuracy of Tree 5 : 0.8430208333333333\n",
      "Classes:  [1 8 5 3 4 2 6 9 7 0]\n",
      "SLP input dimension: 100\n",
      "SLP Weights: Parameter containing:\n",
      "tensor([[ 9.4129e-01, -5.3340e-02, -2.4032e-01, -1.1786e-01, -1.6744e-01,\n",
      "         -1.0716e-01, -1.3956e-01, -3.3742e-02, -7.0885e-02, -7.7221e-02,\n",
      "          9.9209e-01, -1.5274e-01, -1.9399e-01, -1.5047e-01, -1.5634e-01,\n",
      "         -2.2406e-01, -1.9988e-02, -8.5024e-02, -1.4190e-01, -1.6925e-01,\n",
      "          1.1102e+00, -4.8348e-02, -1.5684e-01,  2.4283e-02, -1.3540e-01,\n",
      "         -1.3747e-01, -1.1532e-01, -2.1208e-01, -1.6054e-01, -1.3965e-01,\n",
      "          9.3540e-01, -5.8503e-02, -2.6458e-01, -1.3331e-01, -1.4613e-01,\n",
      "         -2.1149e-01, -1.2484e-01, -4.5611e-02, -2.6368e-02, -7.5236e-02,\n",
      "          9.6623e-01, -1.8060e-01, -6.3848e-02, -1.9363e-01, -2.2144e-01,\n",
      "         -1.4821e-01, -4.3436e-02, -5.2570e-02, -1.5150e-01, -1.2633e-01,\n",
      "          1.0054e+00, -4.1309e-02, -3.6868e-02, -5.1449e-02, -6.4037e-02,\n",
      "         -1.6910e-01, -1.4987e-01, -1.7853e-01, -1.7195e-01, -1.4540e-01,\n",
      "          1.0528e+00, -9.3420e-02, -2.0118e-01, -3.4051e-02, -4.1653e-02,\n",
      "         -1.5676e-01, -1.0354e-01, -1.2701e-01, -2.7975e-02, -3.7093e-02,\n",
      "          9.6923e-01, -1.7654e-01, -6.1695e-02, -8.9669e-03, -4.9312e-02,\n",
      "         -3.8952e-02, -2.1914e-01, -1.8840e-01, -4.0022e-02, -1.7134e-01,\n",
      "          8.8899e-01, -1.1061e-02, -5.6073e-02, -2.0193e-01, -7.7885e-02,\n",
      "         -1.7013e-01, -1.5205e-01, -1.7410e-01, -8.6973e-02, -1.1231e-01,\n",
      "          9.9970e-01, -8.9619e-02, -1.2441e-02, -8.4539e-02, -1.9889e-01,\n",
      "         -1.3815e-01, -1.2111e-01, -1.2779e-01, -1.0269e-01, -2.0297e-01],\n",
      "        [-3.2872e-02,  1.0655e+00, -1.9506e-01, -1.2965e-01, -1.4840e-01,\n",
      "         -1.0412e-01, -1.8256e-01, -1.5788e-01, -1.8777e-01, -7.6717e-02,\n",
      "         -1.6797e-01,  9.8525e-01, -1.6477e-01, -1.8290e-02,  2.9423e-02,\n",
      "         -1.5570e-01, -1.4085e-01, -9.3618e-02, -1.4775e-01, -8.2276e-02,\n",
      "         -9.5541e-02,  1.0205e+00, -1.5032e-01, -5.0550e-02, -1.9526e-01,\n",
      "         -1.2397e-01, -1.5777e-01, -2.0294e-01, -1.8189e-01, -1.6302e-01,\n",
      "         -1.5338e-01,  1.0729e+00, -1.4781e-01, -1.2989e-01,  8.6910e-03,\n",
      "         -1.1265e-01, -1.2136e-01, -1.6168e-01, -1.3787e-01, -5.5289e-02,\n",
      "         -4.3093e-02,  9.7965e-01, -1.0154e-02, -1.2397e-01, -1.6196e-01,\n",
      "         -1.5053e-01, -4.2305e-02, -4.8373e-02, -1.8062e-01, -1.7578e-01,\n",
      "         -2.1270e-01,  9.4197e-01, -8.3054e-02, -7.9092e-02, -3.8615e-02,\n",
      "         -1.4540e-01, -6.6438e-02, -2.5994e-01, -1.8978e-01, -1.2984e-01,\n",
      "         -1.5314e-01,  8.8378e-01, -1.9697e-01, -2.0538e-01, -1.1046e-01,\n",
      "         -9.4369e-02, -9.9597e-02, -7.0941e-02, -2.0857e-01, -7.6047e-02,\n",
      "         -4.5802e-02,  9.7085e-01, -8.5611e-02, -8.6391e-02, -1.4497e-01,\n",
      "         -4.9491e-02, -5.9298e-02, -1.9412e-01, -5.0416e-02, -1.7298e-01,\n",
      "         -8.7171e-02,  9.9165e-01, -7.9882e-02, -6.6166e-02, -5.5946e-02,\n",
      "         -3.2826e-02, -1.2697e-01, -1.2695e-01, -2.5017e-01, -7.4499e-02,\n",
      "         -6.0398e-02,  1.1267e+00, -1.8105e-01, -1.2594e-01, -1.5604e-01,\n",
      "         -1.6845e-01, -1.3214e-01, -1.1523e-01, -1.9927e-01, -1.2050e-01],\n",
      "        [-7.3149e-02, -1.1403e-01,  1.1162e+00, -1.7314e-01, -1.9246e-01,\n",
      "         -8.6347e-02, -1.3410e-01, -5.0844e-02, -1.3140e-01, -1.2804e-01,\n",
      "         -1.2080e-01, -1.4828e-01,  9.9853e-01, -1.5145e-01, -1.2407e-01,\n",
      "         -1.2354e-02, -1.9275e-01, -1.8059e-01, -6.1190e-02, -1.5331e-01,\n",
      "         -1.5314e-01, -2.2874e-02,  1.1690e+00, -1.4424e-01, -1.9421e-01,\n",
      "         -7.3346e-02, -1.1769e-01, -1.8192e-01, -1.8909e-01, -1.4562e-01,\n",
      "         -9.8272e-02, -3.3807e-02,  1.0954e+00, -9.1524e-02, -5.5426e-02,\n",
      "         -1.6753e-01, -6.8792e-02, -1.7709e-01, -1.7702e-01, -8.4650e-02,\n",
      "         -4.2812e-03, -3.0113e-02,  9.6068e-01, -1.5837e-01, -4.1997e-02,\n",
      "         -1.9262e-01, -1.3369e-03, -1.8992e-01, -1.4854e-01, -1.8889e-01,\n",
      "         -1.2430e-01, -1.3811e-01,  1.0499e+00, -1.9247e-01, -1.6110e-01,\n",
      "         -1.5366e-01, -1.2752e-01, -4.1064e-02, -1.6468e-01, -1.9219e-01,\n",
      "         -1.9805e-01, -5.5824e-02,  1.1494e+00, -1.3523e-01, -6.9504e-02,\n",
      "         -7.8422e-02, -1.2055e-01, -1.0129e-01, -8.8458e-02, -6.4461e-02,\n",
      "         -1.2529e-01, -2.0800e-01,  1.0026e+00, -2.0785e-01, -1.4454e-01,\n",
      "         -2.0974e-01,  1.1790e-02, -2.1461e-01, -1.1461e-01, -5.5855e-02,\n",
      "         -5.7909e-02, -1.9304e-01,  1.2288e+00, -2.4159e-01, -1.1688e-01,\n",
      "          2.1660e-02, -1.2838e-01, -1.5327e-01, -1.8890e-01, -1.6799e-01,\n",
      "         -1.2545e-01, -5.7345e-02,  1.0207e+00, -1.5929e-01, -1.2574e-01,\n",
      "         -1.4334e-01, -4.9782e-02, -2.3561e-01, -1.2526e-01, -7.6670e-02],\n",
      "        [-1.0993e-01, -5.8741e-02, -9.9791e-02,  1.0857e+00, -1.0561e-01,\n",
      "         -2.4492e-01, -1.3304e-01, -3.9548e-02, -5.9409e-02, -1.7446e-01,\n",
      "         -2.2524e-01, -9.3275e-02, -1.1735e-02,  9.9552e-01, -4.7781e-02,\n",
      "         -1.5203e-01, -1.7203e-01, -4.6836e-02, -6.0512e-03, -1.5013e-01,\n",
      "         -1.0194e-01, -1.0986e-01, -1.1481e-01,  1.1880e+00, -8.3187e-02,\n",
      "         -1.2635e-01, -9.1923e-02, -9.8194e-02,  2.0741e-02, -2.1994e-01,\n",
      "         -1.0976e-01, -2.3192e-01,  4.5569e-02,  1.2488e+00, -2.6958e-01,\n",
      "         -1.2630e-01, -7.4054e-02,  5.6780e-03, -9.6694e-02, -7.0167e-03,\n",
      "         -1.8649e-01, -1.3457e-01,  2.7724e-02,  1.2081e+00, -1.2850e-01,\n",
      "         -7.8827e-02, -7.6634e-02, -7.2947e-02, -1.5371e-01, -1.4253e-01,\n",
      "         -1.4940e-01, -5.4753e-02, -7.0641e-02,  1.0947e+00, -1.0786e-01,\n",
      "         -7.7183e-02, -1.8529e-01, -7.1714e-03, -1.8405e-01, -8.1570e-02,\n",
      "         -1.5705e-01, -2.0199e-01, -1.5878e-01,  1.1945e+00, -5.3220e-02,\n",
      "         -5.5715e-02, -7.3963e-02, -2.0983e-01, -1.6281e-01, -1.4462e-01,\n",
      "         -1.5710e-01, -5.3759e-02, -1.3937e-01,  1.0856e+00, -2.1786e-01,\n",
      "         -1.6712e-01, -6.8411e-02, -1.5830e-04, -4.9765e-02, -1.0622e-01,\n",
      "         -8.2350e-02, -1.2293e-01, -9.6738e-02,  1.3541e+00, -1.0272e-01,\n",
      "         -2.0521e-02, -7.0233e-02, -8.9421e-02, -1.2248e-01, -1.1389e-01,\n",
      "         -1.4245e-01, -1.3090e-01, -3.5048e-02,  1.2520e+00, -1.6248e-01,\n",
      "         -1.6412e-01, -8.4466e-02, -1.7681e-01, -2.2587e-01, -9.6977e-02],\n",
      "        [-1.2287e-02, -9.6356e-02, -9.8001e-02, -6.4514e-02,  1.0262e+00,\n",
      "         -1.9672e-01, -2.6502e-02, -6.6408e-02, -1.6586e-01,  1.8866e-02,\n",
      "         -1.4068e-01, -1.0526e-01, -1.3057e-01, -1.0796e-01,  9.2145e-01,\n",
      "         -7.7985e-02, -1.4987e-01, -2.1384e-01, -3.7297e-02,  6.3234e-02,\n",
      "         -2.1870e-02, -2.2177e-01, -1.7753e-01, -1.2109e-01,  1.0009e+00,\n",
      "         -1.8351e-01, -9.1961e-02, -1.3743e-01, -1.7084e-01,  3.6997e-02,\n",
      "         -1.5795e-01, -8.8046e-02,  3.7872e-03, -1.5360e-01,  1.0147e+00,\n",
      "         -1.7178e-01, -5.1463e-02, -2.3218e-01, -8.0270e-02, -1.6785e-01,\n",
      "         -2.0896e-01, -1.9813e-01, -1.4852e-01, -1.0470e-01,  1.0886e+00,\n",
      "         -4.6407e-02, -1.6852e-01, -1.5332e-01, -1.5388e-01, -1.0190e-01,\n",
      "         -1.3977e-02, -1.0204e-01,  3.8535e-03, -8.4342e-02,  1.1045e+00,\n",
      "         -5.0577e-02, -9.5954e-02, -1.5868e-01, -1.6059e-01, -1.4762e-01,\n",
      "         -2.1317e-01, -1.8381e-01, -1.1663e-01, -2.0952e-01,  1.1182e+00,\n",
      "         -1.0214e-01, -1.2559e-01, -2.2360e-01, -1.6249e-01,  7.7406e-03,\n",
      "         -1.4094e-02, -5.8415e-02, -9.7886e-02, -1.6354e-01,  1.1887e+00,\n",
      "         -1.6456e-01, -2.2472e-01, -1.1342e-01, -1.5096e-01, -7.2031e-02,\n",
      "         -1.4018e-01, -1.7095e-01, -2.9932e-01, -8.2020e-02,  1.1349e+00,\n",
      "         -6.4356e-02, -6.7459e-02, -4.8674e-02, -1.2969e-01, -7.4015e-02,\n",
      "         -9.6655e-02, -1.3148e-01, -1.4215e-01, -1.8166e-01,  1.0686e+00,\n",
      "         -1.2362e-01, -1.1252e-01, -1.9010e-01, -1.8783e-02,  6.4952e-02],\n",
      "        [-2.2574e-01, -7.2582e-02, -8.5356e-02, -5.0426e-02, -5.7874e-02,\n",
      "          1.1558e+00, -5.3764e-02, -8.1514e-02, -2.2749e-01, -1.8962e-01,\n",
      "         -1.5557e-01, -6.6423e-02, -1.4642e-01, -2.1331e-01, -1.2174e-01,\n",
      "          1.1020e+00, -1.3793e-01, -1.0733e-01, -3.1135e-02, -1.6464e-01,\n",
      "         -7.9012e-02, -1.3884e-01, -9.8780e-02, -1.8500e-01, -1.8914e-01,\n",
      "          1.0127e+00, -1.2595e-02, -9.9407e-02, -1.6221e-01, -2.4744e-01,\n",
      "         -1.1578e-02, -2.1794e-02, -2.1107e-01, -2.7318e-01, -1.7173e-01,\n",
      "          1.1907e+00, -1.6551e-01, -1.5396e-01, -1.6669e-01, -2.3327e-01,\n",
      "         -1.4057e-01, -9.1432e-02, -1.4440e-01, -1.2341e-01, -1.3921e-01,\n",
      "          1.1955e+00, -1.9567e-01, -1.2620e-01, -1.7096e-01, -1.4902e-01,\n",
      "         -1.6143e-01, -2.1229e-01, -6.5808e-02, -1.6227e-01, -1.0762e-01,\n",
      "          9.2624e-01, -1.1993e-01, -9.5944e-02, -4.9648e-02, -1.4676e-01,\n",
      "         -2.1782e-01, -1.7886e-01, -1.2181e-01, -6.5774e-02, -2.2195e-01,\n",
      "          1.1032e+00, -8.6212e-02, -1.2546e-01, -2.9671e-02, -1.5564e-01,\n",
      "         -4.4966e-02, -8.3680e-02, -1.5808e-01, -1.6850e-01, -1.4527e-01,\n",
      "          1.0473e+00, -7.0938e-02, -2.0992e-01, -3.4421e-02, -7.9658e-02,\n",
      "         -1.3066e-01, -1.7755e-01, -2.1293e-01, -8.0199e-02, -1.3848e-01,\n",
      "          9.5736e-01, -3.2056e-02, -9.5620e-02, -5.5778e-02, -1.3155e-01,\n",
      "         -1.1593e-01, -2.3481e-01, -2.0587e-01, -6.4706e-02, -8.2295e-02,\n",
      "          1.2071e+00, -2.0980e-01, -5.5262e-02, -6.5635e-02, -7.6610e-02],\n",
      "        [-1.4676e-01, -1.3324e-01, -2.6683e-01, -6.1829e-02, -1.2626e-01,\n",
      "         -1.9990e-01,  1.1518e+00, -1.3695e-01, -1.5694e-01, -1.4694e-01,\n",
      "          4.1479e-03, -1.7147e-01, -9.4211e-02, -2.0287e-01, -6.5976e-02,\n",
      "         -3.4706e-02,  1.0287e+00, -1.0167e-01,  5.3844e-03, -1.2848e-01,\n",
      "         -1.7338e-01,  1.3131e-02, -1.7384e-01, -2.4956e-01, -9.8450e-02,\n",
      "         -1.7913e-01,  1.1714e+00, -1.3780e-01, -1.6950e-01, -1.4061e-01,\n",
      "          4.2727e-02, -7.0367e-02, -1.4278e-01, -1.1671e-01, -1.1876e-02,\n",
      "         -2.0752e-01,  9.6685e-01, -2.1971e-01, -1.5573e-01, -9.9800e-02,\n",
      "         -3.1039e-02, -1.1422e-01, -1.3280e-01, -8.7103e-02, -1.3532e-01,\n",
      "         -1.0158e-01,  9.8247e-01, -9.6080e-03, -2.3561e-01, -1.8128e-01,\n",
      "         -4.0401e-02, -1.1910e-01, -2.4475e-02, -1.8166e-01, -2.1013e-01,\n",
      "         -2.1637e-01,  1.0629e+00, -3.7706e-02, -1.0270e-01, -1.2719e-01,\n",
      "          1.3680e-02, -1.1708e-01, -1.0947e-01, -1.8907e-01, -1.3074e-01,\n",
      "         -5.0822e-02,  1.0086e+00, -3.4322e-02, -1.4083e-01, -7.9227e-02,\n",
      "         -2.6130e-01, -2.0419e-02, -1.7430e-01, -8.5430e-02, -1.2839e-01,\n",
      "         -5.4936e-02,  1.1030e+00, -1.2889e-01, -3.6977e-02, -1.6390e-01,\n",
      "         -2.2555e-02, -1.9255e-01, -7.7770e-02, -1.1545e-01, -9.4877e-02,\n",
      "         -3.0370e-02,  9.7480e-01, -1.9290e-01, -2.4496e-02, -1.2035e-01,\n",
      "          3.0706e-02, -1.6089e-01, -1.3766e-01, -4.8149e-02, -5.9851e-02,\n",
      "         -2.5954e-01,  1.0606e+00, -1.8683e-01, -1.5588e-02, -1.3127e-01],\n",
      "        [-1.4858e-01,  5.2047e-03, -1.7464e-01, -1.0719e-01, -1.1420e-01,\n",
      "         -1.5227e-01, -1.1230e-01,  1.0356e+00, -1.9908e-01,  2.0971e-02,\n",
      "         -1.3293e-01, -1.0147e-01, -1.3278e-01, -1.7365e-01, -2.8198e-02,\n",
      "         -1.6354e-01, -1.2595e-01,  1.1804e+00, -1.0700e-01, -1.0518e-01,\n",
      "         -3.6300e-02, -1.8351e-01, -1.3915e-01, -2.1266e-01, -1.0375e-01,\n",
      "         -7.3503e-02, -4.2327e-02,  1.0163e+00, -1.4734e-01, -6.4018e-02,\n",
      "         -1.2861e-01, -5.4825e-02, -1.0921e-01, -1.1690e-01, -9.9504e-02,\n",
      "         -3.0354e-02, -1.2762e-01,  9.5849e-01, -1.0181e-01, -1.6333e-01,\n",
      "         -1.3129e-01, -3.9196e-02, -3.1459e-02, -1.5217e-01, -1.3227e-01,\n",
      "         -7.5230e-02, -7.1146e-02,  1.0373e+00, -1.4318e-01, -9.0092e-02,\n",
      "         -1.7270e-01, -7.7897e-02, -3.4711e-02, -6.9628e-02, -3.5715e-02,\n",
      "         -1.0368e-01, -1.7793e-01,  1.0687e+00, -1.9987e-01, -7.4005e-02,\n",
      "         -9.4942e-02, -6.5161e-03, -1.6741e-01, -9.3215e-02, -6.8503e-02,\n",
      "         -1.4281e-01, -1.5266e-01,  1.1254e+00, -1.9229e-01, -1.1529e-01,\n",
      "         -6.4993e-02, -2.2226e-01, -8.9705e-02, -9.7998e-02, -6.3146e-02,\n",
      "         -1.3290e-01, -3.0261e-02,  1.0921e+00, -1.0747e-01, -1.0011e-01,\n",
      "         -1.9250e-01, -9.6889e-02, -1.4152e-01, -2.1383e-01, -1.2202e-01,\n",
      "         -1.8339e-01, -1.4207e-01,  9.2829e-01, -8.0969e-02,  1.2842e-01,\n",
      "         -1.2099e-01, -9.1517e-02,  5.0107e-03, -1.7203e-01, -1.0889e-01,\n",
      "         -1.7421e-01, -1.8350e-01,  1.0877e+00, -1.8884e-01, -5.0712e-02],\n",
      "        [-1.3240e-01, -1.8425e-01, -1.0078e-01, -2.6068e-01, -1.4010e-01,\n",
      "         -7.6549e-02, -1.1624e-01, -1.0684e-01,  1.2173e+00,  2.5075e-03,\n",
      "         -2.1610e-01, -1.4747e-01, -5.3700e-02, -1.2396e-01, -1.0834e-01,\n",
      "         -1.0984e-01, -1.6290e-01,  2.0355e-02,  9.7158e-01, -1.1831e-01,\n",
      "         -5.5852e-02, -1.1652e-01, -6.6683e-02, -1.2795e-01, -1.0094e-01,\n",
      "         -1.5865e-01, -1.4173e-01, -2.3584e-01,  1.2010e+00, -2.1314e-01,\n",
      "         -1.8686e-01, -1.0168e-01, -1.1223e-01, -1.7523e-01, -2.1938e-01,\n",
      "         -9.2456e-02, -1.0789e-01, -1.0821e-01,  1.0960e+00, -1.1934e-01,\n",
      "         -2.4425e-01, -4.4851e-03, -1.0657e-01, -1.3860e-01, -1.7025e-01,\n",
      "         -8.4682e-02, -6.1229e-02, -4.3060e-02,  1.1385e+00, -1.0699e-01,\n",
      "         -1.3601e-01, -1.9675e-02, -1.6353e-01, -2.1758e-01, -1.0193e-01,\n",
      "         -1.0784e-01, -1.0788e-01, -1.5477e-01,  1.0730e+00, -2.6458e-01,\n",
      "         -1.6764e-01,  6.6618e-02, -9.8026e-02, -1.3393e-01, -3.6956e-02,\n",
      "         -1.1706e-01, -1.3892e-01, -1.1825e-01,  1.0429e+00, -1.8474e-01,\n",
      "         -1.5086e-01, -7.3617e-02, -1.1197e-01, -5.8948e-02, -1.5788e-01,\n",
      "         -7.9033e-02, -1.0813e-01, -4.9342e-02,  8.9898e-01, -1.5630e-01,\n",
      "         -1.9376e-01, -1.6157e-01, -2.3876e-01,  1.9068e-02, -1.3800e-01,\n",
      "         -1.0844e-01, -9.1723e-02, -1.3328e-01,  1.1098e+00, -5.1200e-02,\n",
      "         -1.9396e-01,  6.9724e-03, -1.0164e-01, -8.3240e-02, -1.8837e-01,\n",
      "         -1.0311e-01, -1.8165e-01, -6.9272e-02,  1.0490e+00, -1.0236e-01],\n",
      "        [-4.2375e-02, -3.1999e-02, -8.7893e-02, -2.0987e-03, -5.4364e-02,\n",
      "         -7.4274e-02, -1.3870e-01, -1.7649e-01, -1.1120e-01,  8.9155e-01,\n",
      "         -8.8406e-02, -7.1268e-02, -8.2479e-02, -9.6849e-02, -4.8020e-02,\n",
      "         -3.2656e-02, -1.8366e-01, -3.1876e-01, -1.2541e-01,  1.1520e+00,\n",
      "         -1.0499e-01, -1.8738e-01, -1.9060e-01, -1.3657e-01, -7.1323e-02,\n",
      "         -1.5497e-01, -6.2339e-02, -1.6969e-01, -9.8095e-02,  1.0952e+00,\n",
      "         -4.1524e-02, -1.9172e-01, -2.4057e-01,  1.5967e-02, -2.2190e-01,\n",
      "         -7.2410e-02, -3.9700e-02, -1.8396e-01, -3.9999e-02,  1.0556e+00,\n",
      "         -1.4477e-01, -1.8941e-01, -1.5958e-01, -1.1769e-01, -2.1656e-01,\n",
      "         -1.2142e-01, -2.2372e-01, -2.6997e-01, -2.9828e-02,  1.1272e+00,\n",
      "         -2.0198e-01, -1.2474e-01, -2.6491e-01, -1.0734e-01, -2.1749e-01,\n",
      "         -3.2784e-02, -1.1020e-01, -1.0544e-01, -5.9693e-02,  1.0332e+00,\n",
      "         -1.7254e-01, -7.3702e-02, -7.1104e-02, -1.4856e-01, -2.4618e-01,\n",
      "         -1.1852e-01, -7.4169e-02, -1.3814e-01, -1.3962e-01,  1.1061e+00,\n",
      "         -9.7418e-02, -7.2002e-02, -6.0881e-02, -4.2978e-02, -2.2154e-01,\n",
      "         -1.2428e-01, -6.8581e-02, -3.0949e-02, -1.7451e-01,  1.1105e+00,\n",
      "         -1.3806e-01, -2.0931e-01, -1.3654e-01, -1.6301e-01, -1.3183e-01,\n",
      "         -1.3167e-01, -1.6857e-01, -6.0581e-02, -1.5801e-01,  9.9500e-01,\n",
      "         -1.5228e-01, -4.9933e-02, -7.3417e-02, -1.6993e-01, -1.2640e-01,\n",
      "         -9.3400e-02, -8.5273e-02, -1.0086e-01, -3.9441e-02,  9.6226e-01]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "0.9419166666666666\n"
     ]
    }
   ],
   "source": [
    "sgfc = SlpGeneticForestClassifier(N=10, generation_number=0, class_percentage = 1)\n",
    "sgfc.fit(X_train, y_train)\n",
    "pred=sgfc.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(np.array([[1, 0], [1,1],[2,2],[1,3],[1,4],[1,5],[1,6],[1,7],[1,8],[1,9]]))\n",
    "one_hot_encoded_predictions = enc.transform(np.array([[1,1],[1,3]])).toarray() \n",
    "print(one_hot_encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303541666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = X_train.sample(frac=1, replace=True, random_state=190)\n",
    "len(sample.index.unique())/len(sample.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 4, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(10*0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_label = np.random.choice(range(10), 3, replace=False)\n",
    "y_train_subset = y_train[y_train.label.isin(filter_label)]\n",
    "X_train_subset = X_train.loc[y_train_subset.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6311666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [i for i in range(60000)]\n",
    "slected_lst = np.random.choice(lst, 60000, replace=True)\n",
    "len(np.unique(slected_lst))/len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6340833333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "slected_lst = []\n",
    "for i in range(60000):\n",
    "    rnd = np.random.randint(60000)\n",
    "    slected_lst.append(rnd)\n",
    "len(np.unique(slected_lst))/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03014696828331853"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tree': 2, 'accuracy': 4, 'filter_label': 5}, {'tree': 4, 'accuracy': 3, 'filter_label': 2}]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "newlist = sorted([{\"tree\": 4, \"accuracy\": 3, \"filter_label\": 2},{\"tree\": 2, \"accuracy\": 4, \"filter_label\": 5}], key=itemgetter('accuracy'), reverse=True)\n",
    "print(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08 0.04 0.  ]\n",
      "[0.66666667 0.33333333 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['a'], dtype='<U1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = ['a','b','c']\n",
    "accuracies = [0.98, 0.94,0.9]\n",
    "accuracies -= np.min(accuracies)\n",
    "print(accuracies)\n",
    "probabilities = np.asarray(accuracies)/sum(accuracies)\n",
    "print(probabilities)\n",
    "np.random.choice(lst, 1, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label\n",
      "40228      0\n",
      "56085      8\n",
      "5007       0\n",
      "40115      0\n",
      "38310      0\n",
      "...      ...\n",
      "33673      0\n",
      "37954      0\n",
      "41983      9\n",
      "45066      0\n",
      "51708      9\n",
      "\n",
      "[3601 rows x 1 columns]\n",
      "[4 4 4 ... 4 4 3]\n"
     ]
    }
   ],
   "source": [
    "y_train_subset = y_train[y_train.label.isin([3,4])]\n",
    "X_train_subset = X_train.loc[y_train_subset.index]\n",
    "X_train_subtree = X_train_subset.sample(frac=1, replace=True, random_state=1)\n",
    "Y_train_subtree = y_train_subset.sample(frac=1, replace=True, random_state=1)\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "dtc = dtc.fit(X_train_subtree,Y_train_subtree)\n",
    "y_valid_filtered= y_test[y_test.label.isin(filter_label)]\n",
    "X_valid_filtered = X_test.loc[y_valid_filtered.index]\n",
    "y_pred = dtc.predict(X_valid_filtered)\n",
    "print(y_valid_filtered)\n",
    "print(y_pred)\n",
    "tree_accuracy = metrics.accuracy_score(y_valid_filtered, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
