{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from threading import Thread\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torchvision                                 \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn                              \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, d, K):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.model = nn.Linear(d, K)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.model(x.float())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGeneticForestClassifier:\n",
    "    def __init__(self, N, generation_number, class_percentage):\n",
    "        self.N = N\n",
    "        self.generation_number = generation_number\n",
    "        self.class_percentage = class_percentage\n",
    "        self.trained_trees = []\n",
    "        self.slp = None\n",
    "        self.prediction_tree = None\n",
    "        self.one_hot_encoder = None\n",
    "        self.SEED = 0          \n",
    "        self.EPOCHS = 20          \n",
    "        self.LR = 0.01            # learning rate\n",
    "        self.MOMENTUM = 0.9       # momentum for the optimizer\n",
    "        self.WEIGHT_DECAY = 1e-5  #\n",
    "        self.GAMMA = 0.1          # learning rate schedular\n",
    "        self.BATCH_SIZE = 32      # number of images to load per iteration\n",
    "        \n",
    "        self.train_tree_batch = 20\n",
    "        self.mutation_rate = 0.2\n",
    "        self.population_list = None\n",
    "\n",
    "    def train_net(self):\n",
    "        self.slp.train()\n",
    "        epoch_loss = 0.0\n",
    "        for xt, rt in self.train_loader:\n",
    "            xt, rt = xt.to(self.device), rt.to(self.device)\n",
    "            self.optimizer.zero_grad() \n",
    "            yt = self.slp(xt)\n",
    "            loss = self.loss_fn(yt, rt)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        return epoch_loss\n",
    "        \n",
    "    def train_tree(self, filter_label, state_counter, tree_list):\n",
    "        \n",
    "        y_train_subtree = self.y_train[self.y_train.label.isin(filter_label)]\n",
    "        X_train_subtree = self.X_train.loc[y_train_subtree.index.values.tolist()]\n",
    "        \n",
    "        dtc = DecisionTreeClassifier(random_state=state_counter)\n",
    "        dtc = dtc.fit(X_train_subtree,y_train_subtree)\n",
    "        y_valid_filtered= self.y_valid[self.y_valid.label.isin(filter_label)]\n",
    "        X_valid_filtered = self.X_valid.loc[y_valid_filtered.index]\n",
    "        y_pred = dtc.predict(X_valid_filtered)\n",
    "        tree_accuracy = metrics.accuracy_score(y_valid_filtered, y_pred)\n",
    "        print(state_counter+1, end=\" \")\n",
    "        tree_list.append({\"tree\": dtc, \"accuracy\": tree_accuracy, \"filter_label\": filter_label})   \n",
    "        \n",
    "    def fit_trees(self, filter_labels, tree_list):\n",
    "        print(\"Started to train {} trees.\".format(len(filter_labels)))\n",
    "        print(\"Trained Trees: \", end=\"\")\n",
    "        state_counter = 0\n",
    "        train_threads = []\n",
    "        for filter_label in filter_labels:\n",
    "            train_threads.append(Thread(target=self.train_tree, args=[filter_label, state_counter, tree_list]))\n",
    "            state_counter += 1\n",
    "        for thread_index in range(0, len(train_threads), self.train_tree_batch ):\n",
    "            current_train_threads = train_threads[thread_index:thread_index+self.train_tree_batch ]\n",
    "            for train_thread in current_train_threads:\n",
    "                train_thread.start()\n",
    "            for train_thread in current_train_threads:\n",
    "                train_thread.join()\n",
    "        print(\"\\n{} Trees are trained.\".format(len(filter_labels)))\n",
    "                \n",
    "    def train_slp(self, one_hot_encoded_predictions):\n",
    "        print(\"Started to train SLP.\")\n",
    "        self.d = one_hot_encoded_predictions.shape[1]      # number of input features \n",
    "        \n",
    "        # manual seed to reproduce same resultsnet\n",
    "        torch.manual_seed(self.SEED)\n",
    "        \n",
    "        self.slp = Perceptron(self.d,self.K)\n",
    "        cuda = torch.cuda.is_available()  \n",
    "        self.device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "        self.slp.to(self.device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.slp.parameters(), lr=self.LR, momentum=self.MOMENTUM, weight_decay=self.WEIGHT_DECAY)\n",
    "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=self.GAMMA) #CHECK THIS\n",
    "        \n",
    "        train_target = torch.tensor(self.y_train.values.flatten().astype(np.int32)).long()\n",
    "\n",
    "        train = torch.tensor(one_hot_encoded_predictions) \n",
    "\n",
    "        train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "        self.train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = self.BATCH_SIZE, shuffle = True, num_workers=8)\n",
    "        \n",
    "        # train the network\n",
    "        for epoch in range(1,self.EPOCHS+1):\n",
    "            self.train_net()\n",
    "        print(\"SLP is trained.\")\n",
    "        \n",
    "    def one_hot_encode(self, total_predictions):\n",
    "        self.one_hot_encoder = OneHotEncoder(handle_unknown='ignore') \n",
    "        self.one_hot_encoder.fit(total_predictions)\n",
    "        \n",
    "        one_hot_encoded_predictions = self.one_hot_encoder.transform(total_predictions).toarray() \n",
    "        return one_hot_encoded_predictions\n",
    "\n",
    "    \n",
    "    def train_prediction_tree(self, one_hot_encoded_predictions):\n",
    "        self.prediction_tree = DecisionTreeClassifier(random_state=200)\n",
    "        self.prediction_tree = self.prediction_tree.fit(one_hot_encoded_predictions, self.y_train)\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.sample_count = y_train.shape[0]\n",
    "        self.K = self.label_count              # number of output features\n",
    "        \n",
    "        self.population_list = self.genetic_find_parameters()\n",
    "        last_population = self.population_list[-1]\n",
    "        \n",
    "        self.trained_trees = [member['tree'] for member in last_population]\n",
    "        \n",
    "        total_predictions = self.forest_trees_predict(self.X_train)\n",
    "        one_hot_encoded_predictions = self.one_hot_encode(total_predictions)\n",
    "        self.train_slp(one_hot_encoded_predictions)\n",
    "        self.train_prediction_tree(total_predictions)\n",
    "        \n",
    "    def model_analysis(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  # Train-test split pairs\n",
    "        self.label_count = len(y_train.label.unique())\n",
    "        self.sample_count = y_train.shape[0]\n",
    "        self.K = self.label_count              # number of output features\n",
    "        \n",
    "        self.population_list = self.genetic_find_parameters()\n",
    "        \n",
    "        majority_accuracies = []\n",
    "        slp_accuracies = []\n",
    "        prediction_tree_accuracies = []\n",
    "        population_mean_accuracies = []\n",
    "        \n",
    "        for population in self.population_list:\n",
    "            \n",
    "            population_mean_accuracy = np.mean(np.asarray([member['accuracy'] for member in population]))\n",
    "            population_mean_accuracies.append(population_mean_accuracy)\n",
    "\n",
    "            self.trained_trees = [member['tree'] for member in population]\n",
    "            total_predictions = self.forest_trees_predict(self.X_train)\n",
    "            one_hot_encoded_predictions = self.one_hot_encode(total_predictions)\n",
    "            self.train_slp(one_hot_encoded_predictions)\n",
    "            self.train_prediction_tree(total_predictions)\n",
    "            \n",
    "            majority_voting_pred = self.majority_voting_predict(X_test)\n",
    "            slp_pred = self.slp_predict(X_test)\n",
    "            prediction_tree_predict = self.prediction_tree_predict(X_test)\n",
    "            \n",
    "            majority_accuracy = metrics.accuracy_score(y_test, majority_voting_pred)\n",
    "            slp_accuracy = metrics.accuracy_score(y_test, slp_pred)\n",
    "            prediction_tree_accuracy = metrics.accuracy_score(y_test, prediction_tree_predict)\n",
    "            \n",
    "            majority_accuracies.append(majority_accuracy)\n",
    "            slp_accuracies.append(slp_accuracy)\n",
    "            prediction_tree_accuracies.append(prediction_tree_accuracy)\n",
    "        generation_numbers = np.arange(len(self.population_list))\n",
    "        return generation_numbers, prediction_tree_accuracies, slp_accuracies, majority_accuracies, population_mean_accuracies\n",
    "        \n",
    "    \n",
    "    def majority_voting_predict(self, X_test):\n",
    "        total_predictions = self.forest_trees_predict(X_test)\n",
    "        # Majority Voting\n",
    "        predicted_values = []\n",
    "        for row in total_predictions:\n",
    "            majority_vote = np.bincount(row).argmax()\n",
    "            predicted_values.append(majority_vote)\n",
    "        y_pred_class = np.asarray(predicted_values)\n",
    "        return y_pred_class\n",
    "    \n",
    "    def slp_predict(self, X_test):\n",
    "        total_predictions = self.forest_trees_predict(X_test)\n",
    "        # SLP\n",
    "        one_hot_encoded_predictions = self.one_hot_encoder.transform(total_predictions).toarray() \n",
    "        test = torch.tensor(one_hot_encoded_predictions) \n",
    "        y_pred = self.slp(test.to(self.device))\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred_class = np.asarray([np.argmax(pred) for pred in y_pred])\n",
    "        return y_pred_class\n",
    "    \n",
    "    def prediction_tree_predict(self, X_test):\n",
    "        total_predictions = self.forest_trees_predict(X_test)\n",
    "        # Prediction Tree\n",
    "        y_pred_class = self.prediction_tree.predict(total_predictions)\n",
    "        return y_pred_class\n",
    "    \n",
    "    def forest_trees_predict(self, X_test):\n",
    "        total_predictions = self.trained_trees[0].predict(X_test)\n",
    "        for i in range(1, self.N):\n",
    "            total_predictions = np.vstack([total_predictions, self.trained_trees[i].predict(X_test)])\n",
    "        total_predictions = np.transpose(total_predictions)\n",
    "        return total_predictions\n",
    "    \n",
    "    \n",
    "    # Genetic algorithm  \n",
    "    def generate_parent_samples(self):\n",
    "        generation = []\n",
    "        for i in range(self.N):\n",
    "            generation.append(np.random.choice(range(self.label_count), round(self.label_count*self.class_percentage), replace=False))\n",
    "        return generation  \n",
    "\n",
    "\n",
    "    def genetic_find_parameters(self):\n",
    "        print(\"Genetic algorithm is started.\")\n",
    "        generation = self.generate_parent_samples()\n",
    "        population_list = []\n",
    "        for i in range(self.generation_number+1):\n",
    "            print(\"Generation:\",i)\n",
    "            trained_tree_results = []\n",
    "            self.fit_trees(generation, trained_tree_results)\n",
    "            population_list.append(trained_tree_results)\n",
    "            generation = self.evolve(trained_tree_results)\n",
    "        print(\"\\nGenetic algorithm is ended.\")\n",
    "        return population_list\n",
    "    \n",
    "        \n",
    "    def evolve(self, trained_tree_results):\n",
    "        \n",
    "        trained_tree_results_sorted = sorted(trained_tree_results, key=itemgetter(\"accuracy\"), reverse=True)\n",
    "        \n",
    "        next_generation = []\n",
    "        \n",
    "        # Elitism\n",
    "        next_generation.append(trained_tree_results_sorted[0][\"filter_label\"])\n",
    "        for i in range(1, len(trained_tree_results)):\n",
    "            parent_1 = self.tournament(trained_tree_results)\n",
    "            parent_2 = self.tournament(trained_tree_results)\n",
    "            child = self.crossover(parent_1, parent_2)\n",
    "            child = self.mutate(child)  \n",
    "            next_generation.append(child)        \n",
    "        return next_generation\n",
    "\n",
    "    \n",
    "    def crossover(self, parent1, parent2):\n",
    "        parents_merged = np.unique(np.append(parent1, parent2))\n",
    "        child = np.random.choice(parents_merged, len(parent1), replace=False)\n",
    "        return np.sort(child)\n",
    "\n",
    "    \n",
    "    def mutate(self, child):\n",
    "        mutated_child = []\n",
    "        if len(child) == self.label_count:\n",
    "            return child\n",
    "        non_existing_labels = []\n",
    "        for label in range(self.label_count):\n",
    "            if label not in child:\n",
    "                non_existing_labels.append(label)\n",
    "        for gen in child:\n",
    "            if np.random.random() < self.mutation_rate:\n",
    "                selected_label_index = np.random.randint(len(non_existing_labels))\n",
    "                mutated_child.append(non_existing_labels.pop(selected_label_index))\n",
    "            else:\n",
    "                mutated_child.append(gen)\n",
    "        return np.sort(mutated_child)\n",
    "\n",
    "    def tournament(self, generation):\n",
    "        accuracies = np.asarray([tree[\"accuracy\"] for tree in generation])\n",
    "        accuracies -= np.min(accuracies)\n",
    "        probabilities = np.asarray(accuracies)/sum(accuracies)\n",
    "        selected = np.random.choice(generation, 1, p=probabilities)[0][\"filter_label\"]\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(60) # reproducability\n",
    "\n",
    "def mnist_dataset_read(path):\n",
    "    mndata = MNIST(path)\n",
    "\n",
    "    # read training images and corresponding labels\n",
    "    tr_images, tr_labels = mndata.load_training()\n",
    "    # read test images and corresponding labels\n",
    "    tt_images, tt_labels = mndata.load_testing()\n",
    "\n",
    "    # convert lists into numpy format and apply normalization\n",
    "    tr_images = np.array(tr_images) / 255. # shape (60000, 784)\n",
    "    tr_labels = np.array(tr_labels)         # shape (60000,)\n",
    "    tt_images = np.array(tt_images) / 255. # shape (10000, 784)\n",
    "    tt_labels = np.array(tt_labels)         # shape (10000,)\n",
    "\n",
    "    columns_images = ['p{}'.format(i+1) for i in range(784)]\n",
    "    X_train = pd.DataFrame(data=tr_images, columns=columns_images)\n",
    "    y_train = pd.DataFrame(data=tr_labels, columns=['label'])\n",
    "    X_test = pd.DataFrame(data=tt_images, columns=columns_images)\n",
    "    y_test = pd.DataFrame(data=tt_labels, columns=['label'])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_data(btch):\n",
    "    labels = btch[b'labels']\n",
    "    imgs = btch[b'data'].reshape((-1, 32, 32, 3))\n",
    "    \n",
    "    res = []\n",
    "    for ii in range(imgs.shape[0]):\n",
    "        img = imgs[ii].copy()\n",
    "        img = np.fliplr(np.rot90(np.transpose(img.flatten().reshape(3,32,32)), k=-1))\n",
    "        res.append(img)\n",
    "    imgs = np.stack(res)\n",
    "    return labels, imgs\n",
    "\n",
    "def load_data_cifar():\n",
    "    batch1 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"Datasets/cifar-10-batches-py/data_batch_5\")\n",
    "    test_batch = unpickle(\"Datasets/cifar-10-batches-py/test_batch\")\n",
    "    \n",
    "    pixel_num = 32*32*3\n",
    "    x_train_l = []\n",
    "    y_train_l = []\n",
    "    for ibatch in [batch1, batch2, batch3, batch4, batch5]:\n",
    "        labels, imgs = load_data(ibatch)\n",
    "        x_train_l.append(imgs)\n",
    "        y_train_l.extend(labels)\n",
    "    x_train = np.vstack(x_train_l)\n",
    "    y_train = np.vstack(y_train_l)\n",
    "    \n",
    "    x_test_l = []\n",
    "    y_test_l = []\n",
    "    labels, imgs = load_data(test_batch)\n",
    "    x_test_l.append(imgs)\n",
    "    y_test_l.extend(labels)\n",
    "    x_test = np.vstack(x_test_l)\n",
    "    y_test = np.vstack(y_test_l)\n",
    "    \n",
    "    del batch1, batch2, batch3, batch4, batch5, test_batch\n",
    "    \n",
    "    x_train, x_test = x_train.reshape(-1, pixel_num), x_test.reshape(-1, pixel_num)\n",
    "    \n",
    "    columns_images = ['p{}'.format(i+1) for i in range(pixel_num)]\n",
    "    X_train = pd.DataFrame(data=x_train, columns=columns_images)\n",
    "    y_train = pd.DataFrame(data=y_train, columns=['label'])\n",
    "    X_test = pd.DataFrame(data=x_test, columns=columns_images)\n",
    "    y_test = pd.DataFrame(data=y_test, columns=['label'])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genetic_analysis(generation_numbers, prediction_tree_accuracies, slp_accuracies, majority_accuracies, population_mean_accuracies, dataset_name):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(generation_numbers, prediction_tree_accuracies, marker=\"o\", label = \"Prediction Tree\")\n",
    "    plt.plot(generation_numbers, slp_accuracies, marker=\"o\", label = \"SLP\")\n",
    "    plt.plot(generation_numbers, majority_accuracies, marker=\"o\", label = \"Majority Voting\")\n",
    "    plt.plot(generation_numbers, population_mean_accuracies, marker=\"o\", label = \"Population Mean*\")\n",
    "    plt.title(\"Accuracies of Generations ({} Dataset)\\n\".format(dataset_name), fontsize=25)\n",
    "    plt.xlabel(\"\\nGeneration Number\\n\\n * Population mean accuracy is calculated for each tree only by using data from their train labels.\", fontsize=15)\n",
    "    plt.ylabel(\"Accuracy\\n\", fontsize=20)\n",
    "    plt.legend(loc='lower right', prop={'size': 15})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_train, m_X_test, m_y_train, m_y_test = mnist_dataset_read('Datasets/MNIST')\n",
    "fm_X_train, fm_X_test, fm_y_train, fm_y_test = mnist_dataset_read('Datasets/Fashion_MNIST')\n",
    "c_X_train, c_y_train, c_X_test, c_y_test = load_data_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgfc = CustomGeneticForestClassifier(N=200, generation_number=10, class_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_generation_numbers, m_prediction_tree_accuracies, m_slp_accuracies, m_majority_accuracies, m_population_mean_accuracies = cgfc.model_analysis(m_X_train, m_y_train, m_X_test, m_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genetic_analysis(m_generation_numbers, m_prediction_tree_accuracies, m_slp_accuracies, m_majority_accuracies, m_population_mean_accuracies, dataset_name = \"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(m_generation_numbers)):\n",
    "    print(\"Generation \", m_generation_numbers[i], \":\", end=\" \") \n",
    "    print(\"\\tSLP:{}\\tMajority Voting:{}\\tPrediction Tree:{}\\tPopulation Mean Accuracy:{}\".format(m_slp_accuracies[i], m_majority_accuracies[i], m_prediction_tree_accuracies[i], m_population_mean_accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgfc = CustomGeneticForestClassifier(N=200, generation_number=10, class_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_generation_numbers, fm_prediction_tree_accuracies, fm_slp_accuracies, fm_majority_accuracies, fm_population_mean_accuracies = cgfc.model_analysis(fm_X_train, fm_y_train, fm_X_test, fm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genetic_analysis(fm_generation_numbers, fm_prediction_tree_accuracies, fm_slp_accuracies, fm_majority_accuracies, fm_population_mean_accuracies, dataset_name = \"Fashion MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fm_generation_numbers)):\n",
    "    print(\"Generation \", fm_generation_numbers[i], \":\", end=\" \") \n",
    "    print(\"\\tSLP:{}\\tMajority Voting:{}\\tPrediction Tree:{}\\tPopulation Mean Accuracy:{}\".format(fm_slp_accuracies[i], fm_majority_accuracies[i], fm_prediction_tree_accuracies[i], fm_population_mean_accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgfc = CustomGeneticForestClassifier(N=200, generation_number=10, class_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_generation_numbers, c_prediction_tree_accuracies, c_slp_accuracies, c_majority_accuracies, c_population_mean_accuracies = cgfc.model_analysis(c_X_train, c_y_train, c_X_test, c_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_genetic_analysis(c_generation_numbers, c_prediction_tree_accuracies, c_slp_accuracies, c_majority_accuracies, c_population_mean_accuracies, dataset_name = \"Cifar-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(c_generation_numbers)):\n",
    "    print(\"Generation \", c_generation_numbers[i], \":\", end=\" \") \n",
    "    print(\"\\tSLP:{}\\tMajority Voting:{}\\tPrediction Tree:{}\\tPopulation Mean Accuracy:{}\".format(c_slp_accuracies[i], c_majority_accuracies[i], c_prediction_tree_accuracies[i], c_population_mean_accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(x_values, accuracies, title, x_label):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for algorithm, accuracies in accuracies.items():\n",
    "        plt.plot(x_values, accuracies, marker=\"o\", label = algorithm)\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.xlabel(\"\\n{}\".format(x_label), fontsize=15)\n",
    "    plt.ylabel(\"Accuracy\\n\", fontsize=20)\n",
    "    plt.legend(loc='lower right', prop={'size': 15})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(X_train, X_test, y_train, y_test, tree_number, generation_number, class_percentage):\n",
    "    cgfc = CustomGeneticForestClassifier(N=tree_number, generation_number = generation_number, class_percentage = class_percentage)\n",
    "    cgfc.fit(X_train, y_train)\n",
    "    slp_pred=cgfc.slp_predict(X_test)\n",
    "    prediction_tree_pred=cgfc.prediction_tree_predict(X_test)\n",
    "    majority_voting_pred=cgfc.majority_voting_predict(X_test)\n",
    "    \n",
    "    slp_accuracy = metrics.accuracy_score(y_test, slp_pred)\n",
    "    prediction_tree_accuracy = metrics.accuracy_score(y_test, prediction_tree_pred)\n",
    "    majority_voting_accuracy = metrics.accuracy_score(y_test, majority_voting_pred)\n",
    "    \n",
    "    return slp_accuracy, majority_voting_accuracy, prediction_tree_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_trees_analysis(N_list, X_train, X_test, y_train, y_test):\n",
    "    accuracies_of_N_trees_y = {\"SLP\": [], \"Prediction Tree\": [], \"Majority Voting\": [], \"Random Forest (scikit-learn)\":[]}\n",
    "    for N in N_list:\n",
    "        slp_accuracy, majority_voting_accuracy, prediction_tree_accuracy = get_accuracies(X_train, X_test, y_train, y_test, tree_number = N, generation_number = 0, class_percentage = 0.5)\n",
    "        rf = RandomForestClassifier(n_estimators = N, max_samples = 0.5)\n",
    "        X_train_rf, X_valid_rf, y_train_rf, y_valid_rf = train_test_split(X_train, y_train, test_size=0.2, random_state=0) \n",
    "        rf.fit(X_train_rf, y_train_rf.values.ravel())\n",
    "        rf_pred = rf.predict(X_test)\n",
    "        accuracies_of_N_trees_y[\"Random Forest (scikit-learn)\"].append(metrics.accuracy_score(y_test, rf_pred))\n",
    "        accuracies_of_N_trees_y[\"SLP\"].append(slp_accuracy)\n",
    "        accuracies_of_N_trees_y[\"Prediction Tree\"].append(prediction_tree_accuracy)\n",
    "        accuracies_of_N_trees_y[\"Majority Voting\"].append(majority_voting_accuracy)\n",
    "    return accuracies_of_N_trees_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_percentage_analysis(class_percentage_list, X_train, X_test, y_train, y_test):\n",
    "    accuracies_of_class_percentages_y = {\"SLP\": [], \"Prediction Tree\": [], \"Majority Voting\": []}\n",
    "    for class_percentage in class_percentage_list:\n",
    "        slp_accuracy, majority_voting_accuracy, prediction_tree_accuracy = get_accuracies(X_train, X_test, y_train, y_test, tree_number = 100, generation_number = 5, class_percentage = class_percentage)\n",
    "        accuracies_of_class_percentages_y[\"SLP\"].append(slp_accuracy)\n",
    "        accuracies_of_class_percentages_y[\"Prediction Tree\"].append(prediction_tree_accuracy)\n",
    "        accuracies_of_class_percentages_y[\"Majority Voting\"].append(majority_voting_accuracy)\n",
    "    return accuracies_of_class_percentages_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_list = [i*25 for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_accuracies_of_N_trees_y = number_of_trees_analysis(N_list, m_X_train, m_X_test, m_y_train, m_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Accuracy of Algorithms wrt. Number of Trees (MNIST)\\n\"\n",
    "plot_accuracies(N_list, m_accuracies_of_N_trees_y, plot_title, \"N Trees\")\n",
    "print(m_accuracies_of_N_trees_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_accuracies_of_N_trees_y = number_of_trees_analysis(N_list, fm_X_train, fm_X_test, fm_y_train, fm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Accuracy of Algorithms wrt. Number of Trees (Fashion MNIST)\\n\"\n",
    "plot_accuracies(N_list, fm_accuracies_of_N_trees_y, plot_title, \"N Trees\")\n",
    "print(fm_accuracies_of_N_trees_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_accuracies_of_N_trees_y = number_of_trees_analysis(N_list, c_X_train, c_X_test, c_y_train, c_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Accuracy of Algorithms wrt. Number of Trees (Cifar-10)\\n\"\n",
    "plot_accuracies(N_list, c_accuracies_of_N_trees_y, plot_title, \"N Trees\")\n",
    "print(c_accuracies_of_N_trees_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_percentage_list = [i*0.2 for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_accuracies_of_class_percentages_y = class_percentage_analysis(class_percentage_list, m_X_train, m_X_test, m_y_train, m_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Accuracy of Algorithms wrt. Class Percentage (MNIST)\\n\"\n",
    "plot_accuracies(class_percentage_list, m_accuracies_of_class_percentages_y, plot_title, \"Class Percentage\")\n",
    "print(m_accuracies_of_class_percentages_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_accuracies_of_class_percentages_y = class_percentage_analysis(class_percentage_list, fm_X_train, fm_X_test, fm_y_train, fm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Accuracy of Algorithms wrt. Class Percentage (Fashion MNIST)\\n\"\n",
    "plot_accuracies(class_percentage_list, fm_accuracies_of_class_percentages_y, plot_title, \"Class Percentage\")\n",
    "print(fm_accuracies_of_class_percentages_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_accuracies_of_class_percentages_y = class_percentage_analysis(class_percentage_list, c_X_train, c_X_test, c_y_train, c_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = \"Accuracy of Algorithms wrt. Class Percentage (Cifar-10)\\n\"\n",
    "plot_accuracies(class_percentage_list, c_accuracies_of_class_percentages_y, plot_title, \"Class Percentage\")\n",
    "print(c_accuracies_of_class_percentages_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c1a41f08b160e8c5316af8c8759825f66bc42e51b3e7a5810edb97d91356c55b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}